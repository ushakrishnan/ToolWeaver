# How Programmatic Tool Calling Works - Deep Dive

## High-Level Overview

Programmatic Tool Calling is an **Anthropic pattern** where instead of the LLM directly calling tools through loop iterations, the LLM generates **Python orchestration code** that runs in a sandbox and calls tools programmatically.

### The Key Insight

```
TRADITIONAL LOOP:
LLM â†’ Call Tool A â†’ LLM â†’ Call Tool B â†’ LLM â†’ Call Tool C
      (inference 1)      (inference 2)      (inference 3)
      ~20+ round trips, massive context pollution

PROGRAMMATIC:
LLM â†’ Generate Code â†’ Sandbox Executes Code
                      Tool A â†’ Tool B â†’ Tool C
                      Tool D (parallel)
                      Processing & aggregation
                      Return final result
      ~1-2 round trips, 60-80% latency reduction
```

---

## Architecture: Step-by-Step

### Phase 1: Tool Definition & Catalog Registration

When a **new MCP is added**, it follows this flow:

```python
# 1. DEFINE THE TOOL IN ToolCatalog
from orchestrator.shared.models import ToolCatalog, ToolDefinition, ToolParameter

catalog = ToolCatalog(source="example", version="1.0")

# Add a new MCP tool
catalog.add_tool(ToolDefinition(
    name="get_expenses",           # Unique identifier
    type="mcp",                    # Type: mcp, function, code_exec, or agent
    description="Fetch expense reports by user",
    domain="finance",              # Domain for sharding
    parameters=[
        ToolParameter(
            name="user_id",
            type="string",
            description="User identifier",
            required=True
        ),
        ToolParameter(
            name="quarter",
            type="string",
            description="Q1-Q4 or 'all'",
            required=False,
            default="all"
        )
    ]
))
```

**Code Reference**: [ToolCatalog](../../orchestrator/shared/models.py#L100-L150)

---

## Phase 2: Stub Generation (Progressive Disclosure)

When `ProgrammaticToolExecutor` is initialized with `enable_stubs=True`:

```python
executor = ProgrammaticToolExecutor(
    catalog,
    enable_stubs=True,      # Generate importable stubs
    stub_dir=Path("./stubs")
)
```

The `StubGenerator` automatically creates importable Python stubs:

```
stubs/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ finance/
â”‚   â”‚   â”œâ”€â”€ get_expenses.py
â”‚   â”‚   â”œâ”€â”€ compute_tax.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ hr/
â”‚   â”‚   â”œâ”€â”€ get_team_members.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ (generated module structure)
```

**Generated stub example** (`stubs/tools/finance/get_expenses.py`):

```python
# AUTO-GENERATED - DO NOT EDIT

from pydantic import BaseModel
from typing import Optional

class GetExpensesInput(BaseModel):
    """Input model for get_expenses"""
    user_id: str
    quarter: Optional[str] = "all"

async def get_expenses(user_id: str, quarter: Optional[str] = "all"):
    """Fetch expense reports by user
    
    Args:
        user_id: User identifier
        quarter: Q1-Q4 or 'all'
    
    Returns:
        Expense report data
    """
    from orchestrator.tools.tool_executor import call_tool
    
    parameters = {
        "user_id": user_id,
        "quarter": quarter
    }
    
    result = await call_tool(
        server="finance",
        tool_name="get_expenses",
        parameters=parameters
    )
    return result
```

**Code Reference**: [StubGenerator.generate_all()](../../orchestrator/execution/code_generator.py#L52-L100)

---

## Phase 3: Code Execution Flow

When user code is executed:

```python
code = '''
# Code generated by LLM
from tools.finance import get_expenses
from tools.hr import get_team_members
import asyncio

# Fetch team
team = await get_team_members(department="engineering")
print(f"Team size: {len(team)}")

# Parallel expense lookup
expenses_list = await asyncio.gather(*[
    get_expenses(user_id=m["id"], quarter="Q3")
    for m in team
])

# Process in code (not in LLM context!)
high_spenders = [
    (m["name"], sum(e["amount"] for e in exp))
    for m, exp in zip(team, expenses_list)
    if sum(e["amount"] for e in exp) > 10000
]

print(f"High spenders: {high_spenders}")
'''

result = await executor.execute(code)
```

**Code Reference**: [ProgrammaticToolExecutor.execute()](../../orchestrator/execution/programmatic_executor.py#L114-L300)

---

## The Tool Call Routing Mechanism

### Key Insight: The "Proxy Pattern"

When code calls `await get_expenses(...)`, here's what happens:

```
1. User Code: await get_expenses(user_id="123", quarter="Q3")
                â†“
2. Stub Function Routes To:
   from orchestrator.tools.tool_executor import call_tool
   await call_tool(
       server="finance",           # Domain/server
       tool_name="get_expenses",   # Tool name
       parameters={...}            # Packed params
   )
                â†“
3. Tool Executor Router (call_tool function):
   if server == "finance":  # or any MCP server
       await _execute_mcp_tool(server, tool_name, parameters)
   else:
       await _execute_function(tool_name, parameters)
                â†“
4. MCP Execution (_execute_mcp_tool):
   from orchestrator.infra.mcp_client import MCPClientShim
   
   client = MCPClientShim()
   result = await client.call_tool(tool_name, parameters)
                â†“
5. MCPClientShim.call_tool():
   - Looks up tool_func in tool_map
   - Executes with retry + circuit breaker
   - Returns result back to code
```

**Code Reference**: 
- [call_tool()](../../orchestrator/tools/tool_executor.py#L25-L60)
- [_execute_mcp_tool()](../../orchestrator/tools/tool_executor.py#L104-L120)
- [MCPClientShim.call_tool()](../../orchestrator/infra/mcp_client.py#L52-L90)

---

## How a New MCP Gets Integrated

### Step-by-Step: Adding a New MCP Tool

#### Step 1: Register the Tool in MCP Client Shim

**File**: `orchestrator/infra/mcp_client.py`

```python
from ..dispatch.workers import (
    receipt_ocr_worker,
    line_item_parser_worker,
    expense_categorizer_worker,
    fetch_data_worker,  # â† NEW MCP TOOL
)

_tool_map = {
    "receipt_ocr": receipt_ocr_worker,
    "line_item_parser": line_item_parser_worker,
    "expense_categorizer": expense_categorizer_worker,
    "fetch_data": fetch_data_worker,  # â† ADD HERE
}

class MCPClientShim:
    def __init__(self, ...):
        self.tool_map = _tool_map  # â† Automatically uses new tool
```

**Code Reference**: [MCPClientShim initialization](../../orchestrator/infra/mcp_client.py#L8-L50)

#### Step 2: Create Tool Definition

```python
# In your tool catalog setup or discovery
new_tool = ToolDefinition(
    name="fetch_data",
    type="mcp",
    description="Fetch data from external database",
    domain="data_services",
    parameters=[
        ToolParameter(name="query", type="string", required=True),
        ToolParameter(name="limit", type="integer", required=False, default=100)
    ]
)

catalog.add_tool(new_tool)
```

**Code Reference**: [ToolDefinition model](../../orchestrator/shared/models.py#L36-L50)

#### Step 3: Stub Generation (Automatic)

```python
executor = ProgrammaticToolExecutor(catalog, enable_stubs=True)
# â†“ Stubs auto-generated:
# stubs/tools/data_services/fetch_data.py â† Created automatically
# This stub calls call_tool("data_services", "fetch_data", {...})
```

#### Step 4: User Code Can Now Use It

```python
code = '''
from tools.data_services import fetch_data

results = await fetch_data(query="SELECT * FROM users", limit=50)
print(f"Got {len(results)} records")
'''

result = await executor.execute(code)
```

---

## Tool Call Tracking & Logging

The executor tracks every tool call:

```python
# Inside _call_tool_proxy() - intercepts all tool calls
call_record = {
    "tool": tool_def.name,              # "get_expenses"
    "type": tool_def.type,              # "mcp"
    "parameters": parameters,           # {"user_id": "123", "quarter": "Q3"}
    "timestamp": time.time(),           # When call started
    "caller": {
        "type": "stub_import",          # Called from imported stub
        "execution_id": self.execution_id,  # Unique execution ID
        "tool_id": f"tool_call_{self.tool_call_count}"  # Call sequence #
    }
}
self.tool_call_log.append(call_record)

# After execution:
call_record["completed_at"] = time.time()
call_record["duration"] = completed_at - timestamp
call_record["result_size"] = len(str(result))
call_record["error"] = None  # Or error message if failed
```

**Returned in execution result**:

```python
{
    "output": "Got 15 records\n",
    "result": [...],
    "tool_calls": [
        {
            "tool": "get_expenses",
            "type": "mcp",
            "parameters": {...},
            "timestamp": 1702518000.123,
            "duration": 0.456,
            "error": None
        },
        # ... more tool calls
    ],
    "execution_time": 2.34,
    "error": None,
    "execution_id": "ptc_a1b2c3d4"
}
```

**Code Reference**: [Tool call tracking](../../orchestrator/execution/programmatic_executor.py#L142-L185)

---

## Security: Sandboxing & Limits

### Code Validation

Before execution, code is scanned for security violations:

```python
parsed = ast.parse(code)  # Parse Python AST
self._validate_code_safety(parsed)  # Check for dangerous patterns

# Prevents:
# - __import__('os').system(...)
# - eval(), exec()
# - File access outside sandbox
# - Network calls (configurable)
```

### Sandbox Execution

```python
# User code runs in isolated sandbox with:
# - Resource limits (CPU, memory, time)
# - Restricted builtins (no __import__, os, etc.)
# - Tool functions only access via stubs
# - Network isolation (optional)

result = await self.sandbox.execute(wrapped_code, exec_context)

# If timeout or security violation:
# â†’ ExecutionResult with error details
# â†’ Tool calls logged even if code fails
```

**Code Reference**: [Security validation](../../orchestrator/execution/programmatic_executor.py#L600-L650)

---

## Performance Benefits

### Concrete Example

**Scenario**: Get 10 team members â†’ Fetch expenses for each â†’ Aggregate results

#### Traditional Tool Calling Loop
```
Inference 1: LLM sees all tools, generates:
  "Call get_team_members()"
  Context: ~50KB (all tools)
  
Inference 2: LLM sees team list (15 people), generates:
  "Call get_expenses for person 1"
  Context: ~50KB (all tools) + team data
  
Inference 3-11: Repeat for each person
  Total: ~11 inferences Ã— 50KB context = 550KB tokens
  
Inference 12: Aggregate and return result
```

**Total: 12 inferences, ~550KB tokens, 2-3 minutes latency**

#### Programmatic Tool Calling
```
Inference 1: LLM generates:
  "from tools.hr import get_team_members
   from tools.finance import get_expenses
   import asyncio
   
   team = await get_team_members()
   expenses = await asyncio.gather(*[
       get_expenses(u['id']) for u in team
   ])
   ..."
  Context: ~50KB (showed only imported tools, not full catalog)
  
Execution (Sandbox):
  - Call get_team_members() â†’ 15 people in ~0.5s
  - Parallel call get_expenses() for all 15 â†’ ~10 async calls in ~1s
  - Process results in Python (no LLM) â†’ loops, aggregation in ~0.1s
  - Return final summary
```

**Total: 1 inference, ~50KB tokens, 2-3 seconds latency**

### Metrics from Benchmarks

```
Latency Reduction:     60-80% (2-3 mins â†’ 2-3 secs)
Token Savings:         37% (intermediate data stays in sandbox)
Tool Calls Per Task:   1 inference vs 20+
Memory Usage:          Lower (no repeated context duplication)
Cost Reduction:        50-60% fewer tokens
```

---

## Complete Code Example: Adding New MCP + Using It

### Example: Adding "Slack Send Message" Tool

#### 1. Create Worker (if not exists)

```python
# orchestrator/dispatch/workers.py

async def slack_send_message(payload):
    """MCP worker for Slack message sending"""
    channel = payload["channel"]
    text = payload["text"]
    
    # Call actual Slack API
    from slack_sdk.web.async_client import AsyncWebClient
    
    client = AsyncWebClient(token=os.getenv("SLACK_TOKEN"))
    response = await client.chat_postMessage(
        channel=channel,
        text=text
    )
    return {
        "ts": response["ts"],
        "channel": response["channel"]
    }
```

#### 2. Register in Tool Map

```python
# orchestrator/infra/mcp_client.py

from ..dispatch.workers import slack_send_message  # â† Add import

_tool_map = {
    # ... existing tools ...
    "slack_send_message": slack_send_message,  # â† Add to map
}
```

#### 3. Create Tool Definition

```python
# In your application
from orchestrator.shared.models import ToolCatalog, ToolDefinition, ToolParameter

catalog = ToolCatalog(source="myapp", version="1.0")
catalog.add_tool(ToolDefinition(
    name="slack_send_message",
    type="mcp",
    description="Send a message to a Slack channel",
    domain="slack",
    parameters=[
        ToolParameter(
            name="channel",
            type="string",
            description="Channel ID or name",
            required=True
        ),
        ToolParameter(
            name="text",
            type="string",
            description="Message text",
            required=True
        )
    ]
))
```

#### 4. Use in Programmatic Code

```python
from orchestrator.programmatic_executor import ProgrammaticToolExecutor

executor = ProgrammaticToolExecutor(catalog)

code = '''
from tools.slack import slack_send_message

# Notify team
await slack_send_message(
    channel="engineering",
    text="Deployment completed successfully!"
)

print("Message sent!")
'''

result = await executor.execute(code)
print(result["output"])  # "Message sent!"
```

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM (Claude, GPT-4, etc.)                                 â”‚
â”‚  Receives: Tool definitions + Task                         â”‚
â”‚  Generates: Python orchestration code                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Code String (orchestration logic)   â”‚
        â”‚ from tools.slack import send_msg... â”‚
        â”‚ from tools.db import query...       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ProgrammaticToolExecutor.execute(code)     â”‚
        â”‚                                             â”‚
        â”‚ 1. Validate code safety (AST check)        â”‚
        â”‚ 2. Inject tool wrappers + context          â”‚
        â”‚ 3. Patch call_tool routing                 â”‚
        â”‚ 4. Execute in sandbox                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 SANDBOX ENVIRONMENT                   â”‚
        â”‚                                                       â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ Generated Stubs (in memory or from disk)      â”‚  â”‚
        â”‚  â”‚                                                â”‚  â”‚
        â”‚  â”‚ from tools.slack import send_message          â”‚  â”‚
        â”‚  â”‚ async def send_message(...):                  â”‚  â”‚
        â”‚  â”‚     await call_tool("slack", "send_message"..â”‚  â”‚
        â”‚  â”‚                                                â”‚  â”‚
        â”‚  â”‚ from tools.db import query                    â”‚  â”‚
        â”‚  â”‚ async def query(...):                         â”‚  â”‚
        â”‚  â”‚     await call_tool("db", "query", ...)      â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚                          â†‘                             â”‚
        â”‚                          â”‚ (calls route back)         â”‚
        â”‚                          â”‚                             â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ User Code Execution                           â”‚  â”‚
        â”‚  â”‚                                                â”‚  â”‚
        â”‚  â”‚ team = await get_team_members(dept="eng")     â”‚  â”‚
        â”‚  â”‚ expenses = await asyncio.gather(*[             â”‚  â”‚
        â”‚  â”‚     get_expenses(u['id']) for u in team       â”‚  â”‚
        â”‚  â”‚ ])                                             â”‚  â”‚
        â”‚  â”‚ high_spenders = [...]  # Process in Python    â”‚  â”‚
        â”‚  â”‚ print(json.dumps(high_spenders))              â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚                                                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Tool Call Router: orchestrator/tools/tool_executor.py
        â”‚                                                   â”‚
        â”‚ call_tool(server, tool_name, parameters)         â”‚
        â”‚   â†“                                               â”‚
        â”‚   if server == "slack":                          â”‚
        â”‚       â†’ _execute_mcp_tool()                      â”‚
        â”‚   elif server == "default":                      â”‚
        â”‚       â†’ _execute_function()                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                                                   â”‚
        â†“ MCP Tools                                â†“ Function Tools          â”‚
        â”‚                                          â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚ MCPClientShim         â”‚         â”‚ Function Dispatcher      â”‚        â”‚
    â”‚ tool_map = {          â”‚         â”‚                          â”‚        â”‚
    â”‚   "send_message":     â”‚         â”‚ dispatch_tool_call()     â”‚        â”‚
    â”‚     worker_func,      â”‚         â”‚                          â”‚        â”‚
    â”‚   ...                 â”‚         â”‚ Routes to:               â”‚        â”‚
    â”‚ }                     â”‚         â”‚   orchestrator/dispatch/ â”‚        â”‚
    â”‚                       â”‚         â”‚   functions.py           â”‚        â”‚
    â”‚ Retry + Circuit       â”‚         â”‚                          â”‚        â”‚
    â”‚ Breaker               â”‚         â”‚ Timeout + Error handling â”‚        â”‚
    â”‚                       â”‚         â”‚                          â”‚        â”‚
    â”‚ result = await        â”‚         â”‚ result = await dispatch_ â”‚        â”‚
    â”‚  worker_func(**params)â”‚         â”‚  tool_call({...})        â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
            â†“                                 â†“                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
        â”‚ Actual Implementation (MCP Servers or Functions)           â”‚    â”‚
        â”‚                                                             â”‚    â”‚
        â”‚ - Slack API calls                                          â”‚    â”‚
        â”‚ - Database queries                                         â”‚    â”‚
        â”‚ - External service integrations                            â”‚    â”‚
        â”‚ - Python function execution                                â”‚    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                                                                            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Results Back to Code  â”‚
                    â”‚ (via await)           â”‚
                    â”‚                       â”‚
                    â”‚ {"ts": "123...",      â”‚
                    â”‚  "channel": "eng"}    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Execution Complete                    â”‚
                    â”‚                                       â”‚
                    â”‚ {                                     â”‚
                    â”‚   "output": "...",                    â”‚
                    â”‚   "result": {...},                    â”‚
                    â”‚   "tool_calls": [...],               â”‚
                    â”‚   "execution_time": 1.23,            â”‚
                    â”‚   "error": None                       â”‚
                    â”‚ }                                     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Files Reference

| File | Purpose |
|------|---------|
| [orchestrator/execution/programmatic_executor.py](../../../orchestrator/execution/programmatic_executor.py) | Main executor - orchestrates tool calls, validates code, manages execution |
| [orchestrator/execution/code_generator.py](../../../orchestrator/execution/code_generator.py) | Generates type-safe Python stubs from tool definitions |
| [orchestrator/tools/tool_executor.py](../../../orchestrator/tools/tool_executor.py) | Router that dispatches tool calls to appropriate backend (MCP or function) |
| [orchestrator/infra/mcp_client.py](../../../orchestrator/infra/mcp_client.py) | MCP client shim - holds tool_map, handles retries & circuit breaking |
| [orchestrator/shared/models.py](../../../orchestrator/shared/models.py) | Tool and catalog models - defines ToolDefinition, ToolParameter, ToolCatalog |
| [orchestrator/dispatch/workers.py](../../../orchestrator/dispatch/workers.py) | Worker functions - actual MCP tool implementations |
| [orchestrator/execution/sandbox.py](../../../orchestrator/execution/sandbox.py) | Sandbox environment - isolated execution with security & resource limits |

---

## Summary

When a **new MCP is added**:

1. **Define it** as a `ToolDefinition` in the catalog
2. **Register it** in `MCPClientShim.tool_map` (or auto-discovered)
3. **Generate stubs** automatically for progressive disclosure
4. **LLM uses it** in generated code via imports
5. **Stubs route calls** through `call_tool()` â†’ `_execute_mcp_tool()` â†’ `MCPClientShim.call_tool()` â†’ actual worker
6. **All calls tracked** with timing, parameters, errors
7. **Results aggregated** - final response returned to user

The magic is that **tool calls happen in code, not in LLM loops** - achieving 60-80% latency reduction!

---

## ğŸ“š Learn More & See Examples

To see **complete working examples** of adding new tools:

- **[Example 23: Adding New Tools](../../../examples/23-adding-new-tools/)** 
  - Full end-to-end code showing:
    - Creating custom MCP tools with proper schemas
    - Implementing tool workers
    - Registering with MCPClientShim
    - Defining A2A agents
    - Unified discovery of MCP tools + A2A agents
    - Tool metadata and LLM format conversion
  - Files: `add_new_tools.py`, `agents.yaml`, `test_example.py`
  - Run: `cd examples/23-adding-new-tools && python add_new_tools.py`

- **[Example 14: Programmatic Execution](../../../examples/14-programmatic-execution/)**
  - Shows how generated code calls tools programmatically
  - Demonstrates the complete workflow

- **[REFERENCE.md](REFERENCE.md)** - "Adding a New MCP Tool: Checklist"
  - Step-by-step checklist for implementing tools
  - Common patterns and best practices
