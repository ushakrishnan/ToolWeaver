"""
Programmatic Tool Calling Executor

Implements Anthropic's Programmatic Tool Calling pattern:
- LLM generates orchestration code
- Code executes in sandboxed environment with tool access
- Tool calls happen without LLM context pollution
- Only final results return to LLM

Benefits:
- 60-80% latency reduction (1 inference vs 20+)
- 37% token savings (intermediate data stays in sandbox)
- Parallel tool execution via asyncio.gather()
- Complex workflows (loops, filters, aggregations)
"""

import asyncio
import ast
import json
import time
import logging
import uuid
from typing import Dict, Any, List, Optional, Callable
from contextlib import redirect_stdout
from io import StringIO

from orchestrator.models import ToolCatalog, ToolDefinition


class SecurityError(Exception):
    """Raised when code violates security constraints"""
    pass


class ProgrammaticToolExecutor:
    """
    Execute LLM-generated code that orchestrates tool calls
    
    Example:
        executor = ProgrammaticToolExecutor(tool_catalog)
        
        code = '''
        team = await get_team_members("engineering")
        expenses = await asyncio.gather(*[get_expenses(m["id"], "Q3") for m in team])
        exceeded = [m["name"] for m, exp in zip(team, expenses) if sum(e["amount"] for e in exp) > 10000]
        print(json.dumps(exceeded))
        '''
        
        result = await executor.execute(code)
        print(result["output"])  # ["Alice", "Bob"]
        print(f"Called {len(result['tool_calls'])} tools in {result['execution_time']:.2f}s")
    """
    
    def __init__(
        self,
        tool_catalog: ToolCatalog,
        timeout: int = 30,
        max_tool_calls: int = 100,
        logger: Optional[logging.Logger] = None
    ):
        """
        Initialize programmatic executor
        
        Args:
            tool_catalog: Available tools to inject into execution environment
            timeout: Maximum execution time in seconds
            max_tool_calls: Maximum number of tool calls allowed
            logger: Optional logger instance
        """
        self.tool_catalog = tool_catalog
        self.timeout = timeout
        self.max_tool_calls = max_tool_calls
        self.logger = logger or logging.getLogger(__name__)
        
        # Track tool calls for billing/monitoring
        self.tool_call_count = 0
        self.tool_call_log: List[Dict[str, Any]] = []
        self.execution_id = f"ptc_{uuid.uuid4().hex[:8]}"
    
    async def execute(
        self,
        code: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Execute code that orchestrates tool calls
        
        Args:
            code: Python code generated by LLM
            context: Variables available to code (e.g., user_id, previous results)
        
        Returns:
            {
                "output": "...",  # stdout from code
                "result": {...},  # Final return value (if any)
                "tool_calls": [...],  # Tools called during execution
                "execution_time": 1.23,
                "error": None  # Or error message if failed
            }
        """
        start_time = time.time()
        self.tool_call_count = 0
        self.tool_call_log = []
        
        # Build execution environment
        exec_globals = {
            "__builtins__": self._get_safe_builtins(),
            "asyncio": asyncio,
            "json": json,
            **(context or {})
        }
        
        # Inject tool functions
        for tool_name, tool_def in self.tool_catalog.tools.items():
            exec_globals[tool_name] = self._create_tool_wrapper(tool_def)
        
        # Capture stdout
        stdout_buffer = StringIO()
        
        try:
            # Parse and validate code
            parsed = ast.parse(code)
            self._validate_code_safety(parsed)
            
            # Execute with timeout
            with redirect_stdout(stdout_buffer):
                result = await asyncio.wait_for(
                    self._exec_async(code, exec_globals),
                    timeout=self.timeout
                )
            
            execution_time = time.time() - start_time
            
            self.logger.info(
                f"Programmatic execution {self.execution_id}: "
                f"{self.tool_call_count} tools called in {execution_time:.2f}s"
            )
            
            return {
                "output": stdout_buffer.getvalue(),
                "result": result,
                "tool_calls": self.tool_call_log,
                "execution_time": execution_time,
                "error": None,
                "execution_id": self.execution_id
            }
            
        except asyncio.TimeoutError:
            execution_time = time.time() - start_time
            error_msg = f"Execution timeout after {self.timeout}s"
            self.logger.error(f"{self.execution_id}: {error_msg}")
            
            return {
                "output": stdout_buffer.getvalue(),
                "result": None,
                "tool_calls": self.tool_call_log,
                "execution_time": execution_time,
                "error": error_msg,
                "execution_id": self.execution_id
            }
        
        except SecurityError as e:
            execution_time = time.time() - start_time
            error_msg = f"Security violation: {str(e)}"
            self.logger.error(f"{self.execution_id}: {error_msg}")
            
            return {
                "output": stdout_buffer.getvalue(),
                "result": None,
                "tool_calls": self.tool_call_log,
                "execution_time": execution_time,
                "error": error_msg,
                "execution_id": self.execution_id
            }
        
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"{type(e).__name__}: {str(e)}"
            self.logger.error(f"{self.execution_id}: {error_msg}")
            
            return {
                "output": stdout_buffer.getvalue(),
                "result": None,
                "tool_calls": self.tool_call_log,
                "execution_time": execution_time,
                "error": error_msg,
                "execution_id": self.execution_id
            }
    
    def _create_tool_wrapper(self, tool_def: ToolDefinition) -> Callable:
        """
        Create async function that wraps tool execution
        
        Example:
            tool_def.name = "get_expenses"
            Returns: async def get_expenses(user_id, quarter): ...
        
        The wrapper:
        - Validates parameters
        - Tracks tool calls
        - Logs caller context (Anthropic pattern)
        - Executes the actual tool
        - Returns result directly
        """
        async def tool_wrapper(**kwargs):
            # Validate parameters
            required_params = [p.name for p in tool_def.parameters if p.required]
            missing = set(required_params) - set(kwargs.keys())
            if missing:
                raise ValueError(f"{tool_def.name}: Missing required parameters: {missing}")
            
            # Check tool call limit
            if self.tool_call_count >= self.max_tool_calls:
                raise RuntimeError(
                    f"Exceeded max tool calls ({self.max_tool_calls}). "
                    f"Consider optimizing your code or increasing the limit."
                )
            
            self.tool_call_count += 1
            
            # Log the call with caller information (Anthropic pattern)
            call_record = {
                "tool": tool_def.name,
                "type": tool_def.type,
                "parameters": kwargs,
                "timestamp": time.time(),
                "caller": {
                    "type": "code_execution",
                    "execution_id": self.execution_id,
                    "tool_id": f"tool_call_{self.tool_call_count}"
                }
            }
            self.tool_call_log.append(call_record)
            
            # Execute the actual tool
            try:
                result = await self._execute_tool(tool_def, kwargs)
                
                call_record["result_size"] = len(str(result))
                call_record["completed_at"] = time.time()
                call_record["duration"] = call_record["completed_at"] - call_record["timestamp"]
                call_record["error"] = None
                
                return result
                
            except Exception as e:
                call_record["error"] = str(e)
                call_record["completed_at"] = time.time()
                call_record["duration"] = call_record["completed_at"] - call_record["timestamp"]
                raise
        
        # Set function name for better debugging
        tool_wrapper.__name__ = tool_def.name
        return tool_wrapper
    
    async def _execute_tool(
        self,
        tool_def: ToolDefinition,
        parameters: Dict[str, Any]
    ) -> Any:
        """
        Execute the actual tool based on its type
        
        Note: We import inside functions to avoid circular dependencies
        """
        if tool_def.type == "mcp":
            # Call MCP worker
            from orchestrator.workers import MCPClientShim
            
            shim = MCPClientShim()
            if tool_def.name not in shim.tool_map:
                raise ValueError(f"MCP tool not found: {tool_def.name}")
            
            tool_func = shim.tool_map[tool_def.name]
            result = await tool_func(**parameters)
            return result
        
        elif tool_def.type == "function":
            # Call function from hybrid dispatcher
            from orchestrator.hybrid_dispatcher import dispatch_tool_call
            
            result = await dispatch_tool_call({
                "tool": "function_call",
                "input": {
                    "name": tool_def.name,
                    "args": parameters
                }
            }, {})
            
            return result
        
        elif tool_def.type == "code_exec":
            # Nested code execution not supported (prevents recursion attacks)
            raise SecurityError(
                "Nested code execution is not allowed. "
                "Move code_exec logic into programmatic calling instead."
            )
        
        else:
            raise ValueError(f"Unknown tool type: {tool_def.type}")
    
    async def _exec_async(self, code: str, exec_globals: Dict) -> Any:
        """
        Execute code that may contain await statements
        
        Wraps code in an async function to support await statements at top level
        """
        # Wrap code in async function
        wrapped_code = "async def __exec_func():\n"
        wrapped_code += "\n".join(f"    {line}" for line in code.split("\n"))
        
        # Execute wrapper definition
        exec(wrapped_code, exec_globals)
        
        # Call the async function
        return await exec_globals["__exec_func"]()
    
    def _validate_code_safety(self, parsed: ast.AST):
        """
        AST-based code validation for security
        
        Blocks:
        - File I/O (open, write, Path)
        - Network calls (socket, requests, urllib)
        - Process spawning (subprocess, os.system)
        - Dangerous imports (pickle, marshal, ctypes)
        - Code execution (eval, exec, compile)
        - Reflection abuse (__import__, getattr with strings)
        - Environment manipulation (os.environ)
        
        Production Note:
        For maximum security, consider additional sandboxing:
        - Docker containers (full isolation)
        - seccomp filters (Linux syscall filtering)
        - Resource limits (memory, CPU, disk)
        """
        forbidden_imports = [
            "pickle", "marshal", "subprocess", "os", "sys",
            "ctypes", "importlib", "__builtin__", "builtins",
            "socket", "urllib", "requests", "http", "httpx",
            "pty", "fcntl", "resource", "signal",
            "pathlib", "shutil", "tempfile"
        ]
        
        forbidden_functions = [
            "eval", "exec", "compile", "__import__",
            "open", "input", "raw_input",
            "delattr", "setattr", "getattr",  # Prevent reflection abuse
            "globals", "locals", "vars", "dir"  # Prevent introspection abuse
        ]
        
        for node in ast.walk(parsed):
            # Check imports
            if isinstance(node, ast.Import):
                for alias in node.names:
                    if alias.name in forbidden_imports:
                        raise SecurityError(f"Forbidden import: {alias.name}")
                    
                    # Block partial matches (e.g., "os.path")
                    base_module = alias.name.split(".")[0]
                    if base_module in forbidden_imports:
                        raise SecurityError(f"Forbidden import: {alias.name}")
            
            # Check from X import Y
            if isinstance(node, ast.ImportFrom):
                if node.module:
                    if node.module in forbidden_imports:
                        raise SecurityError(f"Forbidden import: from {node.module}")
                    
                    # Block partial matches
                    base_module = node.module.split(".")[0]
                    if base_module in forbidden_imports:
                        raise SecurityError(f"Forbidden import: from {node.module}")
            
            # Check function calls
            if isinstance(node, ast.Call):
                if isinstance(node.func, ast.Name):
                    if node.func.id in forbidden_functions:
                        raise SecurityError(f"Forbidden function: {node.func.id}()")
                
                # Check for dangerous attribute access: obj.system()
                if isinstance(node.func, ast.Attribute):
                    if node.func.attr in ["system", "popen", "spawn", "call", "run"]:
                        raise SecurityError(f"Forbidden method: .{node.func.attr}()")
            
            # Check for attempts to modify __builtins__
            if isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name):
                        if target.id in ["__builtins__", "__globals__", "__dict__"]:
                            raise SecurityError(f"Cannot modify: {target.id}")
    
    def _get_safe_builtins(self) -> Dict:
        """
        Return safe subset of builtins
        
        Only includes functions safe for data manipulation:
        - Collection operations (len, range, zip, etc.)
        - Math operations (sum, min, max, etc.)
        - Type conversions (str, int, float, etc.)
        - Data structures (list, dict, set, tuple)
        - Exception classes (for error handling)
        
        Explicitly excludes:
        - File I/O (open)
        - Code execution (eval, exec, compile)
        - Introspection (globals, locals, vars)
        - Input (input, raw_input)
        """
        safe = {
            # Iteration
            "range", "enumerate", "zip", "map", "filter", "iter", "next",
            # Collections
            "len", "list", "dict", "set", "tuple", "frozenset",
            # Math
            "sum", "min", "max", "abs", "round", "pow", "divmod",
            # Strings
            "str", "repr", "format", "ord", "chr",
            # Numbers
            "int", "float", "complex", "bool",
            # Sorting
            "sorted", "reversed",
            # Type checking
            "type", "isinstance", "issubclass",
            # Output
            "print",
            # Constants
            "True", "False", "None",
            # Exception classes (for error handling)
            "Exception", "ValueError", "TypeError", "KeyError", "IndexError",
            "RuntimeError", "AttributeError", "ZeroDivisionError",
            # Other safe operations
            "all", "any", "slice", "hash", "id"
        }
        
        # Build dictionary from __builtins__
        if isinstance(__builtins__, dict):
            return {k: __builtins__[k] for k in safe if k in __builtins__}
        else:
            return {k: getattr(__builtins__, k) for k in safe if hasattr(__builtins__, k)}


# Convenience function for quick usage
async def execute_programmatic_code(
    code: str,
    tool_catalog: ToolCatalog,
    context: Optional[Dict[str, Any]] = None,
    timeout: int = 30
) -> Dict[str, Any]:
    """
    Convenience function to execute programmatic tool calling code
    
    Example:
        result = await execute_programmatic_code(
            code="team = await get_team_members('engineering'); print(len(team))",
            tool_catalog=catalog
        )
        print(result["output"])  # "15"
    """
    executor = ProgrammaticToolExecutor(tool_catalog, timeout=timeout)
    return await executor.execute(code, context)
