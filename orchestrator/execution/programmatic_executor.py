"""
Programmatic Tool Calling Executor

Implements Anthropic's Programmatic Tool Calling pattern:
- LLM generates orchestration code
- Code executes in sandboxed environment with tool access
- Tool calls happen without LLM context pollution
- Only final results return to LLM

Benefits:
- 60-80% latency reduction (1 inference vs 20+)
- 37% token savings (intermediate data stays in sandbox)
- Parallel tool execution via asyncio.gather()
- Complex workflows (loops, filters, aggregations)
"""

import asyncio
import ast
import json
import time
import logging
import uuid
import sys
import tempfile
from typing import Dict, Any, List, Optional, Callable
from contextlib import redirect_stdout
from io import StringIO
from pathlib import Path

from orchestrator.models import ToolCatalog, ToolDefinition
from .code_generator import StubGenerator
from orchestrator.tool_filesystem import ToolFileSystem
from .sandbox import SandboxEnvironment, ExecutionResult, ResourceLimits, create_sandbox


class SecurityError(Exception):
    """Raised when code violates security constraints"""
    pass


class ProgrammaticToolExecutor:
    """
    Execute LLM-generated code that orchestrates tool calls
    
    Example:
        executor = ProgrammaticToolExecutor(tool_catalog)
        
        code = '''
        team = await get_team_members("engineering")
        expenses = await asyncio.gather(*[get_expenses(m["id"], "Q3") for m in team])
        exceeded = [m["name"] for m, exp in zip(team, expenses) if sum(e["amount"] for e in exp) > 10000]
        print(json.dumps(exceeded))
        '''
        
        result = await executor.execute(code)
        print(result["output"])  # ["Alice", "Bob"]
        print(f"Called {len(result['tool_calls'])} tools in {result['execution_time']:.2f}s")
    """
    
    def __init__(
        self,
        tool_catalog: ToolCatalog,
        timeout: int = 30,
        max_tool_calls: int = 100,
        logger: Optional[logging.Logger] = None,
        enable_stubs: bool = True,
        stub_dir: Optional[Path] = None,
        use_sandbox: bool = True,
        sandbox_limits: Optional[ResourceLimits] = None,
    ):
        """
        Initialize programmatic executor
        
        Args:
            tool_catalog: Available tools to inject into execution environment
            timeout: Maximum execution time in seconds
            max_tool_calls: Maximum number of tool calls allowed
            logger: Optional logger instance
            enable_stubs: If True, generate importable stubs for progressive disclosure
            stub_dir: Directory for generated stubs (auto-created if None)
        """
        self.tool_catalog = tool_catalog
        self.timeout = timeout
        self.max_tool_calls = max_tool_calls
        self.logger = logger or logging.getLogger(__name__)
        self.enable_stubs = enable_stubs
        self.use_sandbox = use_sandbox
        
        # Track tool calls for billing/monitoring
        self.tool_call_count = 0
        self.tool_call_log: List[Dict[str, Any]] = []
        self.execution_id = f"ptc_{uuid.uuid4().hex[:8]}"
        
        # Phase 1: Stub generation for progressive disclosure
        self.stub_dir = stub_dir
        self.stubs_generated = False
        self._temp_dir = None
        
        if self.enable_stubs:
            self._prepare_stub_environment()
        
        # Initialize sandbox (Phase 2)
        self.sandbox = create_sandbox(use_docker=False, limits=sandbox_limits)
    
    async def execute(
        self,
        code: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Execute code that orchestrates tool calls
        
        Args:
            code: Python code generated by LLM
            context: Variables available to code (e.g., user_id, previous results)
        
        Returns:
            {
                "output": "...",  # stdout from code
                "result": {...},  # Final return value (if any)
                "tool_calls": [...],  # Tools called during execution
                "execution_time": 1.23,
                "error": None  # Or error message if failed
            }
        """
        start_time = time.time()
        self.tool_call_count = 0
        self.tool_call_log = []
        
        # Build execution environment / context
        exec_context = {
            "json": json,
            **(context or {})
        }
        
        # Inject tool functions
        for tool_name, tool_def in self.tool_catalog.tools.items():
            exec_context[tool_name] = self._create_tool_wrapper(tool_def)
        
        try:
            if self.use_sandbox:
                # Wrap code into async __main__ for sandbox
                wrapped_code = "async def __main__():\n" + "\n".join(
                    f"    {line}" if line.strip() else "" for line in code.split("\n")
                )
                
                # Align sandbox timeout with executor timeout
                if hasattr(self.sandbox, "limits") and self.sandbox.limits:
                    try:
                        self.sandbox.limits.max_duration = float(self.timeout)
                    except Exception:
                        pass
                
                # Execute in sandbox (sandbox enforces its own timeout)
                sres: ExecutionResult = await self.sandbox.execute(wrapped_code, exec_context)
                execution_time = time.time() - start_time
                
                self.logger.info(
                    f"Programmatic execution {self.execution_id}: "
                    f"{self.tool_call_count} tools called in {execution_time:.2f}s"
                )
                
                # Normalize error format to match legacy expectations
                if sres.success:
                    error_val = None
                else:
                    if sres.error_type == "SecurityError":
                        msg = sres.error or "Sandbox security violation"
                        # Ensure 'SyntaxError' token is present for syntax errors
                        if isinstance(msg, str) and "Syntax error" in msg:
                            msg = "SyntaxError: " + msg.split("Syntax error:", 1)[-1].strip()
                        error_val = f"Security violation: {msg}"
                    elif sres.error_type:
                        if sres.error:
                            error_val = f"{sres.error_type}: {sres.error}"
                        else:
                            error_val = sres.error_type
                    else:
                        error_val = sres.error or "Execution failed"

                return {
                    "output": sres.stdout,
                    "result": sres.output,
                    "tool_calls": self.tool_call_log,
                    "execution_time": execution_time,
                    "error": error_val,
                    "execution_id": self.execution_id
                }
            else:
                # Legacy in-process execution path
                exec_globals = {
                    "__builtins__": self._get_safe_builtins(),
                    "asyncio": asyncio,
                    "json": json,
                    **(context or {})
                }
                for tool_name, tool_def in self.tool_catalog.tools.items():
                    exec_globals[tool_name] = self._create_tool_wrapper(tool_def)
                
                stdout_buffer = StringIO()
                parsed = ast.parse(code)
                self._validate_code_safety(parsed)
                with redirect_stdout(stdout_buffer):
                    result = await asyncio.wait_for(
                        self._exec_async(code, exec_globals),
                        timeout=self.timeout
                    )
                execution_time = time.time() - start_time
                self.logger.info(
                    f"Programmatic execution {self.execution_id}: "
                    f"{self.tool_call_count} tools called in {execution_time:.2f}s"
                )
                return {
                    "output": stdout_buffer.getvalue(),
                    "result": result,
                    "tool_calls": self.tool_call_log,
                    "execution_time": execution_time,
                    "error": None,
                    "execution_id": self.execution_id
                }
            
        except asyncio.TimeoutError:
            execution_time = time.time() - start_time
            error_msg = f"Execution timeout after {self.timeout}s"
            self.logger.error(f"{self.execution_id}: {error_msg}")
            
            return {
                "output": stdout_buffer.getvalue() if 'stdout_buffer' in locals() else "",
                "result": None,
                "tool_calls": self.tool_call_log,
                "execution_time": execution_time,
                "error": error_msg,
                "execution_id": self.execution_id
            }
        
        except SecurityError as e:
            execution_time = time.time() - start_time
            error_msg = f"Security violation: {str(e)}"
            self.logger.error(f"{self.execution_id}: {error_msg}")
            
            return {
                "output": stdout_buffer.getvalue(),
                "result": None,
                "tool_calls": self.tool_call_log,
                "execution_time": execution_time,
                "error": error_msg,
                "execution_id": self.execution_id
            }
        
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"{type(e).__name__}: {str(e)}"
            self.logger.error(f"{self.execution_id}: {error_msg}")
            
            return {
                "output": stdout_buffer.getvalue(),
                "result": None,
                "tool_calls": self.tool_call_log,
                "execution_time": execution_time,
                "error": error_msg,
                "execution_id": self.execution_id
            }
    
    def _create_tool_wrapper(self, tool_def: ToolDefinition) -> Callable:
        """
        Create async function that wraps tool execution
        
        Example:
            tool_def.name = "get_expenses"
            Returns: async def get_expenses(user_id, quarter): ...
        
        The wrapper:
        - Validates parameters
        - Tracks tool calls
        - Logs caller context (Anthropic pattern)
        - Executes the actual tool
        - Returns result directly
        """
        async def tool_wrapper(**kwargs):
            # Validate parameters
            required_params = [p.name for p in tool_def.parameters if p.required]
            missing = set(required_params) - set(kwargs.keys())
            if missing:
                raise ValueError(f"{tool_def.name}: Missing required parameters: {missing}")
            
            # Check tool call limit
            if self.tool_call_count >= self.max_tool_calls:
                raise RuntimeError(
                    f"Exceeded max tool calls ({self.max_tool_calls}). "
                    f"Consider optimizing your code or increasing the limit."
                )
            
            self.tool_call_count += 1
            
            # Log the call with caller information (Anthropic pattern)
            call_record = {
                "tool": tool_def.name,
                "type": tool_def.type,
                "parameters": kwargs,
                "timestamp": time.time(),
                "caller": {
                    "type": "code_execution",
                    "execution_id": self.execution_id,
                    "tool_id": f"tool_call_{self.tool_call_count}"
                }
            }
            self.tool_call_log.append(call_record)
            
            # Execute the actual tool
            try:
                result = await self._execute_tool(tool_def, kwargs)
                
                call_record["result_size"] = len(str(result))
                call_record["completed_at"] = time.time()
                call_record["duration"] = call_record["completed_at"] - call_record["timestamp"]
                call_record["error"] = None
                
                return result
                
            except Exception as e:
                call_record["error"] = str(e)
                call_record["completed_at"] = time.time()
                call_record["duration"] = call_record["completed_at"] - call_record["timestamp"]
                raise
        
        # Set function name for better debugging
        tool_wrapper.__name__ = tool_def.name
        return tool_wrapper
    
    async def _execute_tool(
        self,
        tool_def: ToolDefinition,
        parameters: Dict[str, Any]
    ) -> Any:
        """
        Execute the actual tool based on its type
        
        Note: We import inside functions to avoid circular dependencies
        """
        if tool_def.type == "mcp":
            # Call MCP worker
            from orchestrator.workers import MCPClientShim
            
            shim = MCPClientShim()
            if tool_def.name not in shim.tool_map:
                raise ValueError(f"MCP tool not found: {tool_def.name}")
            
            tool_func = shim.tool_map[tool_def.name]
            result = await tool_func(**parameters)
            return result
        
        elif tool_def.type == "function":
            # Call function from hybrid dispatcher
            from orchestrator.hybrid_dispatcher import dispatch_tool_call
            
            result = await dispatch_tool_call({
                "tool": "function_call",
                "input": {
                    "name": tool_def.name,
                    "args": parameters
                }
            }, {})
            
            return result
        
        elif tool_def.type == "code_exec":
            # Nested code execution not supported (prevents recursion attacks)
            raise SecurityError(
                "Nested code execution is not allowed. "
                "Move code_exec logic into programmatic calling instead."
            )
        
        else:
            raise ValueError(f"Unknown tool type: {tool_def.type}")
    
    async def _exec_async(self, code: str, exec_globals: Dict) -> Any:
        """
        Execute code that may contain await statements
        
        Wraps code in an async function to support await statements at top level
        """
        # Wrap code in async function
        wrapped_code = "async def __exec_func():\n"
        wrapped_code += "\n".join(f"    {line}" for line in code.split("\n"))
        
        # Execute wrapper definition
        exec(wrapped_code, exec_globals)
        
        # Call the async function
        return await exec_globals["__exec_func"]()
    
    def _validate_code_safety(self, parsed: ast.AST):
        """
        AST-based code validation for security
        
        Blocks:
        - File I/O (open, write, Path)
        - Network calls (socket, requests, urllib)
        - Process spawning (subprocess, os.system)
        - Dangerous imports (pickle, marshal, ctypes)
        - Code execution (eval, exec, compile)
        - Reflection abuse (__import__, getattr with strings)
        - Environment manipulation (os.environ)
        
        Production Note:
        For maximum security, consider additional sandboxing:
        - Docker containers (full isolation)
        - seccomp filters (Linux syscall filtering)
        - Resource limits (memory, CPU, disk)
        """
        forbidden_imports = [
            "pickle", "marshal", "subprocess", "os", "sys",
            "ctypes", "importlib", "__builtin__", "builtins",
            "socket", "urllib", "requests", "http", "httpx",
            "pty", "fcntl", "resource", "signal",
            "pathlib", "shutil", "tempfile"
        ]
        
        forbidden_functions = [
            "eval", "exec", "compile", "__import__",
            "open", "input", "raw_input",
            "delattr", "setattr", "getattr",  # Prevent reflection abuse
            "globals", "locals", "vars", "dir"  # Prevent introspection abuse
        ]
        
        for node in ast.walk(parsed):
            # Check imports
            if isinstance(node, ast.Import):
                for alias in node.names:
                    if alias.name in forbidden_imports:
                        raise SecurityError(f"Forbidden import: {alias.name}")
                    
                    # Block partial matches (e.g., "os.path")
                    base_module = alias.name.split(".")[0]
                    if base_module in forbidden_imports:
                        raise SecurityError(f"Forbidden import: {alias.name}")
            
            # Check from X import Y
            if isinstance(node, ast.ImportFrom):
                if node.module:
                    if node.module in forbidden_imports:
                        raise SecurityError(f"Forbidden import: from {node.module}")
                    
                    # Block partial matches
                    base_module = node.module.split(".")[0]
                    if base_module in forbidden_imports:
                        raise SecurityError(f"Forbidden import: from {node.module}")
            
            # Check function calls
            if isinstance(node, ast.Call):
                if isinstance(node.func, ast.Name):
                    if node.func.id in forbidden_functions:
                        raise SecurityError(f"Forbidden function: {node.func.id}()")
                
                # Check for dangerous attribute access: obj.system()
                if isinstance(node.func, ast.Attribute):
                    if node.func.attr in ["system", "popen", "spawn", "call", "run"]:
                        raise SecurityError(f"Forbidden method: .{node.func.attr}()")
            
            # Check for attempts to modify __builtins__
            if isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name):
                        if target.id in ["__builtins__", "__globals__", "__dict__"]:
                            raise SecurityError(f"Cannot modify: {target.id}")
    
    def _get_safe_builtins(self) -> Dict:
        """
        Return safe subset of builtins
        
        Only includes functions safe for data manipulation:
        - Collection operations (len, range, zip, etc.)
        - Math operations (sum, min, max, etc.)
        - Type conversions (str, int, float, etc.)
        - Data structures (list, dict, set, tuple)
        - Exception classes (for error handling)
        
        Explicitly excludes:
        - File I/O (open)
        - Code execution (eval, exec, compile)
        - Introspection (globals, locals, vars)
        - Input (input, raw_input)
        """
        safe = {
            # Iteration
            "range", "enumerate", "zip", "map", "filter", "iter", "next",
            # Collections
            "len", "list", "dict", "set", "tuple", "frozenset",
            # Math
            "sum", "min", "max", "abs", "round", "pow", "divmod",
            # Strings
            "str", "repr", "format", "ord", "chr",
            # Numbers
            "int", "float", "complex", "bool",
            # Sorting
            "sorted", "reversed",
            # Type checking
            "type", "isinstance", "issubclass",
            # Output
            "print",
            # Constants
            "True", "False", "None",
            # Exception classes (for error handling)
            "Exception", "ValueError", "TypeError", "KeyError", "IndexError",
            "RuntimeError", "AttributeError", "ZeroDivisionError",
            # Other safe operations
            "all", "any", "slice", "hash", "id"
        }
        
        # Build dictionary from __builtins__
        if isinstance(__builtins__, dict):
            return {k: __builtins__[k] for k in safe if k in __builtins__}
        else:
            return {k: getattr(__builtins__, k) for k in safe if hasattr(__builtins__, k)}
    
    def _prepare_stub_environment(self):
        """
        Generate tool stubs and prepare for progressive disclosure.
        
        Phase 1: Code Execution with Progressive Disclosure
        - Generates Python stubs from ToolCatalog
        - Makes stubs importable via sys.path
        - AI models can explore file tree instead of loading full catalog
        - 30-50% context reduction
        """
        try:
            # Create stub directory
            if self.stub_dir is None:
                self._temp_dir = tempfile.mkdtemp(prefix="toolweaver_stubs_")
                self.stub_dir = Path(self._temp_dir)
            else:
                self.stub_dir = Path(self.stub_dir)
                self.stub_dir.mkdir(parents=True, exist_ok=True)
            
            # Generate stubs
            self.logger.info(f"Generating tool stubs in {self.stub_dir}")
            generator = StubGenerator(self.tool_catalog, self.stub_dir)
            stubs = generator.generate_all()
            
            self.logger.info(f"Generated {len(stubs)} tool stubs")
            
            # Add to sys.path for importing
            stub_path_str = str(self.stub_dir)
            if stub_path_str not in sys.path:
                sys.path.insert(0, stub_path_str)
                self.logger.debug(f"Added {stub_path_str} to sys.path")
            
            # Create ToolFileSystem for exploration
            self.tool_filesystem = ToolFileSystem(self.stub_dir)
            
            self.stubs_generated = True
            self.logger.info("Stub environment ready for progressive disclosure")
            
        except Exception as e:
            self.logger.warning(f"Failed to prepare stub environment: {e}")
            self.logger.warning("Falling back to direct tool injection")
            self.enable_stubs = False
    
    def get_tools_directory_tree(self) -> Optional[str]:
        """
        Get visual representation of tool directory for AI exploration.
        
        Returns:
            Directory tree string, or None if stubs not enabled
        
        Usage in prompts:
            "Available tools are organized in this directory:
            {tree}
            
            You can import tools like:
            from tools.google_drive import get_document, GetDocumentInput"
        """
        if not self.enable_stubs or not hasattr(self, 'tool_filesystem'):
            return None
        
        return self.tool_filesystem.get_directory_tree()
    
    def search_tools(self, query: str) -> List[str]:
        """
        Search for tools by name or description.
        
        Args:
            query: Search query
        
        Returns:
            List of matching tool names
        
        Usage: Allow AI to search tools before importing
        """
        if not self.enable_stubs or not hasattr(self, 'tool_filesystem'):
            # Fallback to catalog keys
            return [name for name in self.tool_catalog.tools.keys() if query.lower() in name.lower()]
        
        return self.tool_filesystem.search_tools(query)
    
    def cleanup(self):
        """Clean up temporary stub directory"""
        if self._temp_dir:
            import shutil
            try:
                # Remove from sys.path
                stub_path_str = str(self.stub_dir)
                if stub_path_str in sys.path:
                    sys.path.remove(stub_path_str)
                
                # Delete temp directory
                shutil.rmtree(self._temp_dir, ignore_errors=True)
                self.logger.debug(f"Cleaned up stub directory: {self._temp_dir}")
            except Exception as e:
                self.logger.warning(f"Failed to cleanup stub directory: {e}")
    
    def __del__(self):
        """Cleanup on deletion"""
        self.cleanup()


# Convenience function for quick usage
async def execute_programmatic_code(
    code: str,
    tool_catalog: ToolCatalog,
    context: Optional[Dict[str, Any]] = None,
    timeout: int = 30
) -> Dict[str, Any]:
    """
    Convenience function to execute programmatic tool calling code
    
    Example:
        result = await execute_programmatic_code(
            code="team = await get_team_members('engineering'); print(len(team))",
            tool_catalog=catalog
        )
        print(result["output"])  # "15"
    """
    executor = ProgrammaticToolExecutor(tool_catalog, timeout=timeout)
    return await executor.execute(code, context)
