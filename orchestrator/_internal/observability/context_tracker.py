"""
Context Tracking System

Monitors token usage across agent executions to measure context efficiency.
Tracks: tool definitions, tool results, user input, model output.

Usage:
    tracker = ContextTracker()
    tracker.add_tool_definitions(5000)  # Tool catalog loaded
    tracker.add_tool_result(1500)        # Tool executed
    breakdown = tracker.get_breakdown()  # Get detailed metrics
"""

import logging
from dataclasses import asdict, dataclass
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    pass

logger = logging.getLogger(__name__)


@dataclass
class ContextBreakdown:
    """Detailed breakdown of context usage"""
    tool_definitions: int
    tool_results: int
    user_input: int
    model_output: int
    total: int

    def to_dict(self) -> dict[str, int]:
        """Convert to dictionary"""
        return asdict(self)


class ContextTracker:
    """
    Monitor token usage in real-time.
    
    Categories:
    - Tool definitions: Size of tool catalog/stubs loaded
    - Tool results: Output from tool executions
    - User input: Original user prompt and context
    - Model output: LLM-generated text
    
    Features:
    - Per-category tracking
    - Reset between executions
    - Detailed breakdown reporting
    """

    def __init__(self) -> None:
        """Initialize tracker with zero counts"""
        self.reset()

    def reset(self) -> None:
        """Reset all counters to zero"""
        self.tool_definitions = 0
        self.tool_results = 0
        self.user_input = 0
        self.model_output = 0
        self.total_tokens = 0

        logger.debug("Context tracker reset")

    def add_tool_definitions(self, tokens: int) -> None:
        """
        Add tokens from tool definitions/catalog.
        
        Args:
            tokens: Number of tokens in tool definitions
        """
        self.tool_definitions += tokens
        self.total_tokens += tokens

        logger.debug(f"Added {tokens} tool definition tokens")

    def add_tool_result(self, tokens: int) -> None:
        """
        Add tokens from tool execution results.
        
        Args:
            tokens: Number of tokens in tool result
        """
        self.tool_results += tokens
        self.total_tokens += tokens

        logger.debug(f"Added {tokens} tool result tokens")

    def add_user_input(self, tokens: int) -> None:
        """
        Add tokens from user input.
        
        Args:
            tokens: Number of tokens in user prompt/context
        """
        self.user_input += tokens
        self.total_tokens += tokens

        logger.debug(f"Added {tokens} user input tokens")

    def add_model_output(self, tokens: int) -> None:
        """
        Add tokens from model output.
        
        Args:
            tokens: Number of tokens generated by LLM
        """
        self.model_output += tokens
        self.total_tokens += tokens

        logger.debug(f"Added {tokens} model output tokens")

    def add_text(self, text: str, category: str = "model_output") -> None:
        """
        Add text and estimate token count.
        
        Args:
            text: Text to measure
            category: Category to add to (tool_definitions, tool_results, 
                     user_input, model_output)
        """
        tokens = self._estimate_tokens(text)

        if category == "tool_definitions":
            self.add_tool_definitions(tokens)
        elif category == "tool_results":
            self.add_tool_result(tokens)
        elif category == "user_input":
            self.add_user_input(tokens)
        elif category == "model_output":
            self.add_model_output(tokens)
        else:
            raise ValueError(f"Unknown category: {category}")

    def _estimate_tokens(self, text: str) -> int:
        """
        Estimate token count from text.
        
        Uses simple heuristic: ~4 characters per token.
        For more accurate counting, use tiktoken library.
        
        Args:
            text: Text to measure
            
        Returns:
            Estimated token count
        """
        # Simple estimation: 4 chars â‰ˆ 1 token
        # This is a rough approximation
        return len(text) // 4

    def get_breakdown(self) -> ContextBreakdown:
        """
        Get detailed breakdown of context usage.
        
        Returns:
            ContextBreakdown with all categories
        """
        return ContextBreakdown(
            tool_definitions=self.tool_definitions,
            tool_results=self.tool_results,
            user_input=self.user_input,
            model_output=self.model_output,
            total=self.total_tokens
        )

    def get_percentage_breakdown(self) -> dict[str, float]:
        """
        Get breakdown as percentages.
        
        Returns:
            Dictionary with percentage of total for each category
        """
        if self.total_tokens == 0:
            return {
                "tool_definitions": 0.0,
                "tool_results": 0.0,
                "user_input": 0.0,
                "model_output": 0.0
            }

        return {
            "tool_definitions": (self.tool_definitions / self.total_tokens) * 100,
            "tool_results": (self.tool_results / self.total_tokens) * 100,
            "user_input": (self.user_input / self.total_tokens) * 100,
            "model_output": (self.model_output / self.total_tokens) * 100
        }

    def print_summary(self) -> None:
        """Print formatted summary of context usage"""
        breakdown = self.get_breakdown()
        percentages = self.get_percentage_breakdown()

        print("\n" + "="*50)
        print("Context Usage Summary")
        print("="*50)
        print(f"Total tokens: {self.total_tokens:,}")
        print("\nBreakdown:")
        print(f"  Tool definitions: {breakdown.tool_definitions:,} "
              f"({percentages['tool_definitions']:.1f}%)")
        print(f"  Tool results:     {breakdown.tool_results:,} "
              f"({percentages['tool_results']:.1f}%)")
        print(f"  User input:       {breakdown.user_input:,} "
              f"({percentages['user_input']:.1f}%)")
        print(f"  Model output:     {breakdown.model_output:,} "
              f"({percentages['model_output']:.1f}%)")
        print("="*50 + "\n")

    def get_metrics(self) -> dict[str, Any]:
        """
        Get metrics for monitoring/logging.
        
        Returns:
            Dictionary with key metrics
        """
        breakdown = self.get_breakdown()
        percentages = self.get_percentage_breakdown()

        return {
            "total_tokens": self.total_tokens,
            "breakdown": breakdown.to_dict(),
            "percentages": percentages,
            "tool_overhead": percentages["tool_definitions"],
            "efficiency_score": (
                100 - percentages["tool_definitions"]
                if self.total_tokens > 0 else 0
            )
        }
