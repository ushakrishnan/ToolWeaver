# ============================================================
# AZURE COMPUTER VISION CONFIGURATION (for OCR)
# ============================================================

AZURE_CV_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/

# Authentication Method:
# Option 1: API Key (if local auth is enabled)
#AZURE_CV_KEY=your-azure-computer-vision-key

# Option 2: Azure AD (if disableLocalAuth is true)
# Set this to 'true' and remove/comment AZURE_CV_KEY
AZURE_USE_AD=true

# OCR Mode: 'mock' for fake data, 'azure' for real Azure CV
OCR_MODE=azure


# ============================================================
# LARGE MODEL PLANNER
# ============================================================

# Provider: openai, azure-openai, anthropic, or gemini
PLANNER_PROVIDER=azure-openai

# Model name (deployment name for Azure OpenAI)
PLANNER_MODEL=gpt-4o

# For Azure OpenAI:
# Option 1: API Key (if local auth is enabled)
#AZURE_OPENAI_API_KEY=your-azure-openai-api-key

# Option 2: Azure AD (if disableLocalAuth is true)
# Set this to 'true' and remove/comment AZURE_OPENAI_API_KEY
#AZURE_OPENAI_USE_AD=true

AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# For OpenAI (if using PLANNER_PROVIDER=openai):
OPENAI_API_KEY=

# For Anthropic (if using PLANNER_PROVIDER=anthropic):
ANTHROPIC_API_KEY=

# For Google Gemini (if using PLANNER_PROVIDER=gemini):
GOOGLE_API_KEY=


# ============================================================
# SMALL MODEL WORKERS (Phi-3, Llama, etc.)
# ============================================================

# Enable small model workers for parsing and categorization
USE_SMALL_MODEL=true

# Backend options: 'ollama' (local), 'transformers' (local), 'azure' (Azure AI Foundry)
SMALL_MODEL_BACKEND=ollama

# Model name
# - For Ollama: 'phi3', 'llama3.2'
# - For Azure: deployment name
WORKER_MODEL=phi3

# Ollama Configuration (if SMALL_MODEL_BACKEND=ollama)
OLLAMA_API_URL=http://localhost:11434

# Azure AI Foundry Configuration (if SMALL_MODEL_BACKEND=azure)
# AZURE_SMALL_MODEL_ENDPOINT=
# AZURE_SMALL_MODEL_KEY=
# Or use Azure AD:
# AZURE_SMALL_MODEL_USE_AD=true


# ============================================================
# VECTOR DATABASE (Qdrant)
# ============================================================
# Choose ONE option below by uncommenting the relevant lines

# Option 1: Local Docker (FREE, unlimited storage, for development)
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=
# QDRANT_COLLECTION=toolweaver_tools

# Option 2: Qdrant Cloud Free Tier ($0/month, 1 GB, 100k vectors, ~2,600 tools)
#QDRANT_URL=https://your-qdrant-cloud-url.us-east-1-1.aws.cloud.qdrant.io
#QDRANT_API_KEY=your-qdrant-api-key
#QDRANT_COLLECTION=toolweaver_tools

# Option 3: Qdrant Cloud Paid (~$25/month, 5 GB, 500k vectors, ~13,000 tools)
# QDRANT_URL=https://xxxxx.us-east-1-0.aws.cloud.qdrant.io
# QDRANT_API_KEY=your-qdrant-cloud-api-key-here
# QDRANT_COLLECTION=toolweaver_tools

# Option 4: Azure Container Instances (~$30/month, self-hosted Qdrant)
# QDRANT_URL=http://toolweaver-qdrant.eastus.azurecontainer.io:6333
# QDRANT_API_KEY=
# QDRANT_COLLECTION=toolweaver_tools


# ============================================================
# DISTRIBUTED CACHE (Redis)
# ============================================================
# Choose ONE option below by uncommenting the relevant lines

# Option 1: Local Docker (FREE, unlimited memory, for development)
# REDIS_URL=redis://localhost:6379
# REDIS_PASSWORD=
# REDIS_FALLBACK_ENABLED=true

# Option 2: Redis Cloud Free Tier ($0/month, 30 MB, for dev/testing/small prod)
#REDIS_URL=redis://your-redis-cloud-url.azure.cloud.redislabs.com:10485
#REDIS_PASSWORD=your-redis-password
#REDIS_FALLBACK_ENABLED=true

# Option 3: Redis Cloud Paid (~$7/month for 100 MB, for production)
# REDIS_URL=redis://redis-12345.c123.us-east-1-2.ec2.cloud.redislabs.com:12345
# REDIS_PASSWORD=your-redis-cloud-password-here
# REDIS_FALLBACK_ENABLED=true

# Option 4: Azure Cache for Redis (Basic C0 $18/month, Standard C1 $45/month)
# Use rediss:// (with double 's') for TLS/SSL connection
# REDIS_URL=rediss://toolweaver-cache.redis.cache.windows.net:6380
# REDIS_PASSWORD=your-azure-redis-primary-key-here
# REDIS_FALLBACK_ENABLED=true

# Cache TTL Configuration (optional, uncomment to customize)
# CATALOG_CACHE_TTL=86400  # 24 hours
# SEARCH_CACHE_TTL=3600    # 1 hour
# EMBEDDING_CACHE_TTL=604800  # 7 days
# TOOL_METADATA_CACHE_TTL=86400  # 24 hours


# ============================================================
# MONITORING & OBSERVABILITY
# ============================================================

# Monitoring Backends: local, wandb, prometheus (comma-separated for multiple)
# Default: local (file-based logging, zero dependencies)
MONITORING_BACKENDS=local

# Local Backend Settings
TOOL_LOGS_DIR=.tool_logs

# ============================================================
# WEIGHTS & BIASES (W&B) - Optional (pip install wandb)
# ============================================================
# Get free API key: https://wandb.ai/settings
# Free tier: Unlimited runs, 100 GB storage

#WANDB_API_KEY=your-wandb-api-key
#WANDB_PROJECT=ToolWeaver
#WANDB_ENTITY=your-wandb-username
#WANDB_RUN_NAME=production-run-1

# ============================================================
# PROMETHEUS - Optional (pip install prometheus-client)
# ============================================================
# Metrics endpoint for Prometheus scraping: http://localhost:8000/metrics

# PROMETHEUS_PORT=8000

# ============================================================
# MONITORING USAGE EXAMPLES
# ============================================================
# local only:              MONITORING_BACKENDS=local
# W&B for experiments:     MONITORING_BACKENDS=wandb
# Prometheus for prod:     MONITORING_BACKENDS=prometheus
# All backends:            MONITORING_BACKENDS=local,wandb,prometheus


# ============================================================
# GITHUB MCP SERVER - Model Context Protocol Integration
# ============================================================
# GitHub's hosted MCP server for programmatic GitHub operations
# Get token from: https://github.com/settings/tokens
# Required scopes: repo, read:org, workflow, read:user

#GITHUB_TOKEN=your-github-personal-access-token
#GITHUB_OWNER=your-github-username

# GitHub MCP Server URL (hosted by GitHub Copilot)
#GITHUB_MCP_SERVER_URL=https://api.githubcopilot.com/mcp/

# Toolsets: repos, issues, pull_requests, actions, code_security, etc.
# Or use 'all' for all toolsets
#GITHUB_MCP_TOOLSETS=repos,issues,pull_requests

# Read-only mode (true/false)
#GITHUB_MCP_READONLY=false

# ============================================================
# ANALYTICS - CHOOSE YOUR BACKEND
# ============================================================

# ANALYTICS BACKEND SELECTION
# Choose: 'sqlite', 'otlp', or 'prometheus'
# - sqlite: Local database (file-based, SQL queries, long retention)
# - otlp: Grafana Cloud push (cloud-native, automatic retention)
# - prometheus: HTTP /metrics endpoint (pull-based, self-hosted Prometheus)
ANALYTICS_BACKEND=otlp

# ============================================================
# OPTION 1: SQLITE BACKEND (Local Database)
# ============================================================
# SQLite Configuration
# SQLite database for analytics time-series data (no installation needed)
ANALYTICS_DB_ENABLED=true
ANALYTICS_DB_PATH=~/.toolweaver/analytics.db

# Database retention (days) - 0 for unlimited
ANALYTICS_DB_RETENTION_DAYS=365

# ============================================================
# OPTION 2: OTLP BACKEND (Grafana Cloud Prometheus)
# ============================================================
# OpenTelemetry Protocol - Push metrics directly to Grafana Cloud
# Simpler than SQLite, no local storage, automatic retention

# Grafana Cloud OTLP endpoint (from Prometheus onboarding)
#OTLP_ENDPOINT=https://otlp-gateway-prod-us-east-2.grafana.net/otlp

# Grafana Cloud instance ID
#OTLP_INSTANCE_ID=1234567

# Grafana Cloud integration token (from Prometheus setup)
#OTLP_TOKEN=glc_your-grafana-cloud-token

# How often to push metrics to Grafana Cloud (seconds)
OTLP_PUSH_INTERVAL=60

# Service identification
OTLP_SERVICE_NAME=toolweaver
OTLP_SERVICE_VERSION=1.0.0

# ============================================================
# OPTION 3: PROMETHEUS BACKEND (HTTP Scraping)
# ============================================================
# Traditional Prometheus pull-based metrics
# Exposes HTTP endpoint that Prometheus scrapes

# Enable Prometheus metrics endpoint
PROMETHEUS_ENABLED=true

# Port for /metrics endpoint
PROMETHEUS_PORT=8000

# Host to bind to (0.0.0.0 = all interfaces, 127.0.0.1 = localhost only)
PROMETHEUS_HOST=0.0.0.0

# ============================================================
# GRAFANA DASHBOARDS (Works with all backends)
# ============================================================
# Grafana Configuration
# Beautiful dashboards for visualizing analytics and metrics
GRAFANA_ENABLED=true

# Grafana URL (Cloud or self-hosted)
# Cloud example: https://myteam-grafana.grafana.net
# Self-hosted example: http://localhost:3000
#GRAFANA_URL=https://your-grafana-instance.grafana.net

# Grafana Service Account Token (from Organization Settings → API Keys → Service Accounts)
# This is your service account token (glsa_... format)
#GRAFANA_API_KEY=glsa_your-grafana-service-account-token

# Data source configuration
GRAFANA_DATASOURCE_NAME=ToolWeaver Analytics
GRAFANA_DATASOURCE_TYPE=sqlite

# Grafana organization ID (default: 1)
GRAFANA_ORG_ID=1

# Auto-create dashboards (true/false)
GRAFANA_AUTO_CREATE_DASHBOARDS=true

# Dashboard refresh interval
GRAFANA_DASHBOARD_REFRESH=1m
