# ============================================================
# AZURE COMPUTER VISION CONFIGURATION (for OCR)
# ============================================================

AZURE_CV_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/

# Authentication Method:
# Option 1: API Key (if local auth is enabled)
#AZURE_CV_KEY=your-azure-computer-vision-key

# Option 2: Azure AD (if disableLocalAuth is true)
# Set this to 'true' and remove/comment AZURE_CV_KEY
AZURE_USE_AD=true

# OCR Mode: 'mock' for fake data, 'azure' for real Azure CV
OCR_MODE=azure


# ============================================================
# LARGE MODEL PLANNER
# ============================================================

# Provider: openai, azure-openai, anthropic, or gemini
PLANNER_PROVIDER=azure-openai

# Model name (deployment name for Azure OpenAI)
PLANNER_MODEL=gpt-4o

# For Azure OpenAI:
# Option 1: API Key (if local auth is enabled)
#AZURE_OPENAI_API_KEY=

# Option 2: Azure AD (if disableLocalAuth is true)
# Set this to 'true' and remove/comment AZURE_OPENAI_API_KEY
AZURE_OPENAI_USE_AD=true

AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# For OpenAI (if using PLANNER_PROVIDER=openai):
OPENAI_API_KEY=

# For Anthropic (if using PLANNER_PROVIDER=anthropic):
ANTHROPIC_API_KEY=

# For Google Gemini (if using PLANNER_PROVIDER=gemini):
GOOGLE_API_KEY=


# ============================================================
# SMALL MODEL WORKERS (Phi-3, Llama, etc.)
# ============================================================

# Enable small model workers for parsing and categorization
USE_SMALL_MODEL=true

# Backend options: 'ollama' (local), 'transformers' (local), 'azure' (Azure AI Foundry)
SMALL_MODEL_BACKEND=ollama

# Model name
# - For Ollama: 'phi3', 'llama3.2'
# - For Azure: deployment name
WORKER_MODEL=phi3

# Ollama Configuration (if SMALL_MODEL_BACKEND=ollama)
OLLAMA_API_URL=http://localhost:11434

# Azure AI Foundry Configuration (if SMALL_MODEL_BACKEND=azure)
# AZURE_SMALL_MODEL_ENDPOINT=
# AZURE_SMALL_MODEL_KEY=
# Or use Azure AD:
# AZURE_SMALL_MODEL_USE_AD=true


# ============================================================
# VECTOR DATABASE (Qdrant)
# ============================================================
# Choose ONE option below by uncommenting the relevant lines

# Option 1: Local Docker (FREE, unlimited storage, for development)
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=
# QDRANT_COLLECTION=toolweaver_tools

# Option 2: Qdrant Cloud Free Tier ($0/month, 1 GB, 100k vectors, ~2,600 tools)
# QDRANT_URL=https://xxxxx.us-east-1-0.aws.cloud.qdrant.io
# QDRANT_API_KEY=your-qdrant-cloud-api-key
# QDRANT_COLLECTION=toolweaver_tools

# Option 3: Qdrant Cloud Paid (~$25/month, 5 GB, 500k vectors, ~13,000 tools)
# QDRANT_URL=https://xxxxx.us-east-1-0.aws.cloud.qdrant.io
# QDRANT_API_KEY=your-qdrant-cloud-api-key-here
# QDRANT_COLLECTION=toolweaver_tools

# Option 4: Azure Container Instances (~$30/month, self-hosted Qdrant)
# QDRANT_URL=http://toolweaver-qdrant.eastus.azurecontainer.io:6333
# QDRANT_API_KEY=
# QDRANT_COLLECTION=toolweaver_tools


# ============================================================
# DISTRIBUTED CACHE (Redis)
# ============================================================
# Choose ONE option below by uncommenting the relevant lines

# Option 1: Local Docker (FREE, unlimited memory, for development)
# REDIS_URL=redis://localhost:6379
# REDIS_PASSWORD=
# REDIS_FALLBACK_ENABLED=true

# Option 2: Redis Cloud Free Tier ($0/month, 30 MB, for dev/testing/small prod)
# REDIS_URL=redis://redis-xxxxx.c56.east-us.azure.cloud.redislabs.com:10485
# REDIS_PASSWORD=your-redis-password
# REDIS_FALLBACK_ENABLED=true

# Option 3: Redis Cloud Paid (~$7/month for 100 MB, for production)
# REDIS_URL=redis://redis-12345.c123.us-east-1-2.ec2.cloud.redislabs.com:12345
# REDIS_PASSWORD=your-redis-cloud-password-here
# REDIS_FALLBACK_ENABLED=true

# Option 4: Azure Cache for Redis (Basic C0 $18/month, Standard C1 $45/month)
# Use rediss:// (with double 's') for TLS/SSL connection
# REDIS_URL=rediss://toolweaver-cache.redis.cache.windows.net:6380
# REDIS_PASSWORD=your-azure-redis-primary-key-here
# REDIS_FALLBACK_ENABLED=true

# Cache TTL Configuration (optional, uncomment to customize)
# CATALOG_CACHE_TTL=86400  # 24 hours
# SEARCH_CACHE_TTL=3600    # 1 hour
# EMBEDDING_CACHE_TTL=604800  # 7 days
# TOOL_METADATA_CACHE_TTL=86400  # 24 hours


# ============================================================
# MONITORING & OBSERVABILITY
# ============================================================

# Monitoring Backends: local, wandb, prometheus (comma-separated for multiple)
# Default: local (file-based logging, zero dependencies)
MONITORING_BACKENDS=local

# Local Backend Settings
TOOL_LOGS_DIR=.tool_logs

# ============================================================
# WEIGHTS & BIASES (W&B) - Optional (pip install wandb)
# ============================================================
# Get free API key: https://wandb.ai/settings
# Free tier: Unlimited runs, 100 GB storage

WANDB_API_KEY=
WANDB_PROJECT=ToolWeaver
WANDB_ENTITY=your-username
WANDB_RUN_NAME=production-run-1

# ============================================================
# PROMETHEUS - Optional (pip install prometheus-client)
# ============================================================
# Metrics endpoint for Prometheus scraping: http://localhost:8000/metrics

# PROMETHEUS_PORT=8000

# ============================================================
# MONITORING USAGE EXAMPLES
# ============================================================
# local only:              MONITORING_BACKENDS=local
# W&B for experiments:     MONITORING_BACKENDS=wandb
# Prometheus for prod:     MONITORING_BACKENDS=prometheus
# All backends:            MONITORING_BACKENDS=local,wandb,prometheus


# ============================================================
# GITHUB MCP SERVER - Model Context Protocol Integration
# ============================================================
# GitHub's hosted MCP server for programmatic GitHub operations
# Get token from: https://github.com/settings/tokens
# Required scopes: repo, read:org, workflow, read:user

GITHUB_TOKEN=
GITHUB_OWNER=

# GitHub MCP Server URL (hosted by GitHub Copilot)
GITHUB_MCP_SERVER_URL=https://api.githubcopilot.com/mcp/

# Toolsets: repos, issues, pull_requests, actions, code_security, etc.
# Or use 'all' for all toolsets
GITHUB_MCP_TOOLSETS=repos,issues,pull_requests

# Read-only mode (true/false)
GITHUB_MCP_READONLY=false
QDRANT_COLLECTION=toolweaver_tools


# ============================================================
# PHASE 7: GPU ACCELERATION - For Fast Embedding Generation
# ============================================================

# Use GPU for embedding generation (if available)
# Automatically detects CUDA (NVIDIA) or MPS (Apple Silicon)
# Set to false to force CPU-only mode
USE_GPU=true

# Pre-compute embeddings at startup to eliminate cold-start latency
# Caches embeddings in memory for ~11s â†’ <100ms improvement
PRECOMPUTE_EMBEDDINGS=true

# Embedding batch size (automatically adjusted for GPU: CPU=32, GPU=128)
EMBEDDING_BATCH_SIZE=32


# ============================================================
# PHASE 7: DISTRIBUTED CACHE (Redis) - For Multiple Instances
# ============================================================

# Redis URL - Choose one option:

# Option 1: Local Docker (FREE)
REDIS_URL=redis://localhost:6379

# Option 2: Local WSL (FREE)
# REDIS_URL=redis://172.xx.xx.xx:6379

# Option 3: Redis Cloud Free Tier (FREE, 30 MB) - RECOMMENDED
# REDIS_URL=redis://redis-12345.c123.us-east-1-2.ec2.cloud.redislabs.com:12345
# REDIS_PASSWORD=your-redis-cloud-password

# Option 4: Azure Cache for Redis (Basic C0: $18/mo, Standard C1: $45/mo)
# REDIS_URL=rediss://toolweaver-cache.redis.cache.windows.net:6380
# REDIS_PASSWORD=your-azure-redis-primary-key

# Redis Password (required for cloud providers, empty for local)
REDIS_PASSWORD=

# Enable fallback to file cache if Redis unavailable
REDIS_FALLBACK_ENABLED=true


# ============================================================
# MONITORING & OBSERVABILITY
# ============================================================

# Monitoring Backends: local, wandb, prometheus (comma-separated for multiple)
# - local: File-based logging (default, no dependencies)
# - wandb: Weights & Biases integration (optional, requires: pip install wandb)
# - prometheus: Prometheus metrics export (optional, requires: pip install prometheus-client)
MONITORING_BACKENDS=local

# Local Backend (default, zero dependencies)
# Directory for log files (JSONL format, daily rotation)
TOOL_LOGS_DIR=.tool_logs

# ============================================================
# WEIGHTS & BIASES (W&B) - Optional
# ============================================================
# Get API key from: https://wandb.ai/settings
# Sign up at: https://wandb.ai/site
# Free tier: Unlimited runs, 100 GB storage
# Team tier: $50/user/month

# Required for W&B backend
# WANDB_API_KEY=your-wandb-api-key-here

# W&B Project Configuration
# WANDB_PROJECT=toolweaver
# WANDB_ENTITY=your-team-name
# WANDB_RUN_NAME=production-run-1

# Features enabled with W&B:
# - Beautiful dashboards for tool usage, latency, errors
# - Experiment comparison (A/B test prompts, models, configs)
# - Team collaboration and shared metrics
# - Version tracking for prompts and configs

# ============================================================
# PROMETHEUS - Optional
# ============================================================
# Metrics endpoint for Prometheus scraping
# Prometheus server will scrape: http://localhost:8000/metrics
# Requires: pip install prometheus-client

# Port for Prometheus metrics HTTP server
# PROMETHEUS_PORT=8000

# Metrics exposed:
# - toolweaver_tool_calls_total (counter)
# - toolweaver_tool_errors_total (counter)
# - toolweaver_tool_latency_seconds (histogram)
# - toolweaver_search_queries_total (counter)
# - toolweaver_cache_hits_total (counter)
# - toolweaver_tokens_total (counter)

# Example Prometheus scrape config (prometheus.yml):
# scrape_configs:
#   - job_name: 'toolweaver'
#     static_configs:
#       - targets: ['localhost:8000']

# Grafana Dashboard available at: https://grafana.com/grafana/dashboards/
# Search for: "Prometheus Python" or create custom dashboard


# ============================================================
# MONITORING USAGE EXAMPLES
# ============================================================

# Example 1: Local only (default, no setup needed)
# MONITORING_BACKENDS=local
# Logs to: .tool_logs/tool_calls_2025-12-16.jsonl

# Example 2: W&B for experiment tracking
# MONITORING_BACKENDS=wandb
# WANDB_API_KEY=your-key
# WANDB_PROJECT=my-toolweaver-project

# Example 3: Prometheus for production
# MONITORING_BACKENDS=prometheus
# PROMETHEUS_PORT=8000

# Example 4: All backends (development + staging + production)
# MONITORING_BACKENDS=local,wandb,prometheus
# WANDB_API_KEY=your-key
# PROMETHEUS_PORT=8000