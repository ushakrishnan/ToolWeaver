# ============================================================
# AZURE COMPUTER VISION CONFIGURATION (for OCR)
# ============================================================

AZURE_CV_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/

# Authentication Method:
# Option 1: API Key (if local auth is enabled)
#AZURE_CV_KEY=your-azure-computer-vision-key

# Option 2: Azure AD (if disableLocalAuth is true)
# Set this to 'true' and remove/comment AZURE_CV_KEY
AZURE_USE_AD=true

# OCR Mode: 'mock' for fake data, 'azure' for real Azure CV
OCR_MODE=azure


# ============================================================
# LARGE MODEL PLANNER
# ============================================================

# Provider: openai, azure-openai, anthropic, or gemini
PLANNER_PROVIDER=azure-openai

# Model name (deployment name for Azure OpenAI)
PLANNER_MODEL=gpt-4o

# For Azure OpenAI:
# Option 1: API Key (if local auth is enabled)
#AZURE_OPENAI_API_KEY=

# Option 2: Azure AD (if disableLocalAuth is true)
# Set this to 'true' and remove/comment AZURE_OPENAI_API_KEY
AZURE_OPENAI_USE_AD=true

AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# For OpenAI (if using PLANNER_PROVIDER=openai):
OPENAI_API_KEY=

# For Anthropic (if using PLANNER_PROVIDER=anthropic):
ANTHROPIC_API_KEY=

# For Google Gemini (if using PLANNER_PROVIDER=gemini):
GOOGLE_API_KEY=


# ============================================================
# SMALL MODEL WORKERS (Phi-3, Llama, etc.)
# ============================================================

# Enable small model workers for parsing and categorization
USE_SMALL_MODEL=true

# Backend options: 'ollama' (local), 'transformers' (local), 'azure' (Azure AI Foundry)
SMALL_MODEL_BACKEND=ollama

# Model name
# - For Ollama: 'phi3', 'llama3.2'
# - For Azure: deployment name
WORKER_MODEL=phi3

# Ollama Configuration (if SMALL_MODEL_BACKEND=ollama)
OLLAMA_API_URL=http://localhost:11434

# Azure AI Foundry Configuration (if SMALL_MODEL_BACKEND=azure)
# AZURE_SMALL_MODEL_ENDPOINT=
# AZURE_SMALL_MODEL_KEY=
# Or use Azure AD:
# AZURE_SMALL_MODEL_USE_AD=true


# ============================================================
# VECTOR DATABASE (Qdrant)
# ============================================================
# Choose ONE option below by uncommenting the relevant lines

# Option 1: Local Docker (FREE, unlimited storage, for development)
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=
# QDRANT_COLLECTION=toolweaver_tools

# Option 2: Qdrant Cloud Free Tier ($0/month, 1 GB, 100k vectors, ~2,600 tools)
# QDRANT_URL=https://xxxxx.us-east-1-0.aws.cloud.qdrant.io
# QDRANT_API_KEY=your-qdrant-cloud-api-key
# QDRANT_COLLECTION=toolweaver_tools

# Option 3: Qdrant Cloud Paid (~$25/month, 5 GB, 500k vectors, ~13,000 tools)
# QDRANT_URL=https://xxxxx.us-east-1-0.aws.cloud.qdrant.io
# QDRANT_API_KEY=your-qdrant-cloud-api-key-here
# QDRANT_COLLECTION=toolweaver_tools

# Option 4: Azure Container Instances (~$30/month, self-hosted Qdrant)
# QDRANT_URL=http://toolweaver-qdrant.eastus.azurecontainer.io:6333
# QDRANT_API_KEY=
# QDRANT_COLLECTION=toolweaver_tools


# ============================================================
# DISTRIBUTED CACHE (Redis)
# ============================================================
# Choose ONE option below by uncommenting the relevant lines

# Option 1: Local Docker (FREE, unlimited memory, for development)
# REDIS_URL=redis://localhost:6379
# REDIS_PASSWORD=
# REDIS_FALLBACK_ENABLED=true

# Option 2: Redis Cloud Free Tier ($0/month, 30 MB, for dev/testing/small prod)
# REDIS_URL=redis://redis-xxxxx.c56.east-us.azure.cloud.redislabs.com:10485
# REDIS_PASSWORD=your-redis-password
# REDIS_FALLBACK_ENABLED=true

# Option 3: Redis Cloud Paid (~$7/month for 100 MB, for production)
# REDIS_URL=redis://redis-12345.c123.us-east-1-2.ec2.cloud.redislabs.com:12345
# REDIS_PASSWORD=your-redis-cloud-password-here
# REDIS_FALLBACK_ENABLED=true

# Option 4: Azure Cache for Redis (Basic C0 $18/month, Standard C1 $45/month)
# Use rediss:// (with double 's') for TLS/SSL connection
# REDIS_URL=rediss://toolweaver-cache.redis.cache.windows.net:6380
# REDIS_PASSWORD=your-azure-redis-primary-key-here
# REDIS_FALLBACK_ENABLED=true

# Cache TTL Configuration (optional, uncomment to customize)
# CATALOG_CACHE_TTL=86400  # 24 hours
# SEARCH_CACHE_TTL=3600    # 1 hour
# EMBEDDING_CACHE_TTL=604800  # 7 days
# TOOL_METADATA_CACHE_TTL=86400  # 24 hours


# ============================================================
# MONITORING & OBSERVABILITY
# ============================================================

# Monitoring Backends: local, wandb, prometheus (comma-separated for multiple)
# Default: local (file-based logging, zero dependencies)
MONITORING_BACKENDS=local

# Local Backend Settings
TOOL_LOGS_DIR=.tool_logs

# ============================================================
# WEIGHTS & BIASES (W&B) - Optional (pip install wandb)
# ============================================================
# Get free API key: https://wandb.ai/settings
# Free tier: Unlimited runs, 100 GB storage

WANDB_API_KEY=
WANDB_PROJECT=ToolWeaver
WANDB_ENTITY=your-username
WANDB_RUN_NAME=production-run-1

# ============================================================
# PROMETHEUS - Optional (pip install prometheus-client)
# ============================================================
# Metrics endpoint for Prometheus scraping: http://localhost:8000/metrics

# PROMETHEUS_PORT=8000

# ============================================================
# MONITORING USAGE EXAMPLES
# ============================================================
# local only:              MONITORING_BACKENDS=local
# W&B for experiments:     MONITORING_BACKENDS=wandb
# Prometheus for prod:     MONITORING_BACKENDS=prometheus
# All backends:            MONITORING_BACKENDS=local,wandb,prometheus


# ============================================================
# GITHUB MCP SERVER - Model Context Protocol Integration
# ============================================================
# GitHub's hosted MCP server for programmatic GitHub operations
# Get token from: https://github.com/settings/tokens
# Required scopes: repo, read:org, workflow, read:user

GITHUB_TOKEN=
GITHUB_OWNER=

# GitHub MCP Server URL (hosted by GitHub Copilot)
GITHUB_MCP_SERVER_URL=https://api.githubcopilot.com/mcp/

# Toolsets: repos, issues, pull_requests, actions, code_security, etc.
# Or use 'all' for all toolsets
GITHUB_MCP_TOOLSETS=repos,issues,pull_requests

# Read-only mode (true/false)
GITHUB_MCP_READONLY=false
QDRANT_COLLECTION=toolweaver_tools


# ============================================================
# PHASE 7: GPU ACCELERATION - For Fast Embedding Generation
# ============================================================

# Use GPU for embedding generation (if available)
# Automatically detects CUDA (NVIDIA) or MPS (Apple Silicon)
# Set to false to force CPU-only mode
USE_GPU=true

# Pre-compute embeddings at startup to eliminate cold-start latency
# Caches embeddings in memory for ~11s → <100ms improvement
PRECOMPUTE_EMBEDDINGS=true

# Embedding batch size (automatically adjusted for GPU: CPU=32, GPU=128)
EMBEDDING_BATCH_SIZE=32


# ============================================================
# PHASE 7: DISTRIBUTED CACHE (Redis) - For Multiple Instances
# ============================================================

# Redis URL - Choose one option:

# Option 1: Local Docker (FREE)
REDIS_URL=redis://localhost:6379

# Option 2: Local WSL (FREE)
# REDIS_URL=redis://172.xx.xx.xx:6379

# Option 3: Redis Cloud Free Tier (FREE, 30 MB) - RECOMMENDED
# REDIS_URL=redis://redis-12345.c123.us-east-1-2.ec2.cloud.redislabs.com:12345
# REDIS_PASSWORD=your-redis-cloud-password

# Option 4: Azure Cache for Redis (Basic C0: $18/mo, Standard C1: $45/mo)
# REDIS_URL=rediss://toolweaver-cache.redis.cache.windows.net:6380
# REDIS_PASSWORD=your-azure-redis-primary-key

# Redis Password (required for cloud providers, empty for local)
REDIS_PASSWORD=

# Enable fallback to file cache if Redis unavailable
REDIS_FALLBACK_ENABLED=true


# ============================================================
# MONITORING & OBSERVABILITY
# ============================================================

# Monitoring Backends: local, wandb, prometheus (comma-separated for multiple)
# - local: File-based logging (default, no dependencies)
# - wandb: Weights & Biases integration (optional, requires: pip install wandb)
# - prometheus: Prometheus metrics export (optional, requires: pip install prometheus-client)
MONITORING_BACKENDS=local

# Local Backend (default, zero dependencies)
# Directory for log files (JSONL format, daily rotation)
TOOL_LOGS_DIR=.tool_logs

# ============================================================
# WEIGHTS & BIASES (W&B) - Optional
# ============================================================
# Get API key from: https://wandb.ai/settings
# Sign up at: https://wandb.ai/site
# Free tier: Unlimited runs, 100 GB storage
# Team tier: $50/user/month

# Required for W&B backend
# WANDB_API_KEY=your-wandb-api-key-here

# W&B Project Configuration
# WANDB_PROJECT=toolweaver
# WANDB_ENTITY=your-team-name
# WANDB_RUN_NAME=production-run-1

# Features enabled with W&B:
# - Beautiful dashboards for tool usage, latency, errors
# - Experiment comparison (A/B test prompts, models, configs)
# - Team collaboration and shared metrics
# - Version tracking for prompts and configs

# ============================================================
# PROMETHEUS - Optional
# ============================================================
# Metrics endpoint for Prometheus scraping
# Prometheus server will scrape: http://localhost:8000/metrics
# Requires: pip install prometheus-client

# Port for Prometheus metrics HTTP server
# PROMETHEUS_PORT=8000

# Metrics exposed:
# - toolweaver_tool_calls_total (counter)
# - toolweaver_tool_errors_total (counter)
# - toolweaver_tool_latency_seconds (histogram)
# - toolweaver_search_queries_total (counter)
# - toolweaver_cache_hits_total (counter)
# - toolweaver_tokens_total (counter)

# Example Prometheus scrape config (prometheus.yml):
# scrape_configs:
#   - job_name: 'toolweaver'
#     static_configs:
#       - targets: ['localhost:8000']

# Grafana Dashboard available at: https://grafana.com/grafana/dashboards/
# Search for: "Prometheus Python" or create custom dashboard


# ============================================================
# MONITORING USAGE EXAMPLES
# ============================================================

# Example 1: Local only (default, no setup needed)
# MONITORING_BACKENDS=local
# Logs to: .tool_logs/tool_calls_2025-12-16.jsonl

# Example 2: W&B for experiment tracking
# MONITORING_BACKENDS=wandb
# WANDB_API_KEY=your-key
# WANDB_PROJECT=my-toolweaver-project

# Example 3: Prometheus for production
# MONITORING_BACKENDS=prometheus
# PROMETHEUS_PORT=8000

# Example 4: All backends (development + staging + production)
# MONITORING_BACKENDS=local,wandb,prometheus
# WANDB_API_KEY=your-key
# PROMETHEUS_PORT=8000
# ============================================================
# PHASE 5: ANALYTICS WITH SQLITE + GRAFANA
# ============================================================

# SQLite Configuration
ANALYTICS_DB_ENABLED=true
ANALYTICS_DB_PATH=~/.toolweaver/analytics.db
ANALYTICS_DB_RETENTION_DAYS=365

# Grafana Configuration
GRAFANA_ENABLED=true
GRAFANA_URL=https://mycompany-grafana.grafana.net
GRAFANA_API_KEY=glc_xxxxxYYYYzzzzzAAAAABBBB
GRAFANA_DATASOURCE_NAME=ToolWeaver Analytics
GRAFANA_DATASOURCE_TYPE=sqlite
GRAFANA_ORG_ID=1
GRAFANA_AUTO_CREATE_DASHBOARDS=true
GRAFANA_DASHBOARD_REFRESH=1m


# ============================================================
# PHASE 5: ANALYTICS - CHOOSE YOUR BACKEND
# ============================================================

# ANALYTICS BACKEND SELECTION
# Choose between 'sqlite' (local database) or 'otlp' (Grafana Cloud Prometheus)
# - sqlite: Local storage, good for development, requires SQLite setup
# - otlp: Cloud-native, push-based, automatic retention, no local storage
ANALYTICS_BACKEND=otlp

# ============================================================
# OPTION 1: SQLITE BACKEND (Local Database)
# ============================================================
# SQLite Configuration
# SQLite database for analytics time-series data
# - Zero installation required (built into Python)
# - Perfect for metrics and usage tracking
# - Supports millions of records efficiently

ANALYTICS_DB_ENABLED=true

# Database file location
# - Default: ~/.toolweaver/analytics.db
# - Auto-created on first use
# - Supports both Linux (~) and Windows (C:\Users\...)
ANALYTICS_DB_PATH=~/.toolweaver/analytics.db

# Database retention policy (days)
# - 0: Keep all data indefinitely
# - 365: Keep 1 year of data (default)
# - 90: Keep 3 months of data (good for demos)
ANALYTICS_DB_RETENTION_DAYS=365

# Optional: SQLite connection string (advanced)
# Format: sqlite:////path/to/analytics.db
# Usually auto-constructed from ANALYTICS_DB_PATH
# ANALYTICS_DB_URL=sqlite:////home/user/.toolweaver/analytics.db


# ============================================================
# OPTION 2: OTLP BACKEND (Grafana Cloud Prometheus)
# ============================================================
# OpenTelemetry Protocol - Push metrics directly to Grafana Cloud
# Simpler than SQLite, no local storage, automatic retention
# Setup: Go to Grafana Cloud → Prometheus → Send Metrics over HTTP → OTEL

# Grafana Cloud OTLP endpoint (from Prometheus onboarding)
# Format: https://otlp-gateway-prod-{region}.grafana.net/otlp
OTLP_ENDPOINT=https://otlp-gateway-prod-us-east-2.grafana.net/otlp

# Grafana Cloud instance ID (numeric ID from onboarding)
OTLP_INSTANCE_ID=1234567

# Grafana Cloud integration token (from Prometheus setup)
# Format: glc_... (starts with glc_)
OTLP_TOKEN=glc_your_token_here

# How often to push metrics to Grafana Cloud (seconds)
# Default: 60 seconds (1 minute)
OTLP_PUSH_INTERVAL=60

# Service identification (optional)
OTLP_SERVICE_NAME=toolweaver
OTLP_SERVICE_VERSION=1.0.0


# ============================================================
# GRAFANA DASHBOARDS (Works with both SQLite and OTLP)
# ============================================================

# Enable/disable Grafana integration
GRAFANA_ENABLED=true

# Grafana Instance URL
# 
# Option 1: Grafana Cloud (Recommended - Free tier available)
# - Sign up: https://grafana.com/auth/sign-up
# - Format: https://YOUR-INSTANCE-NAME.grafana.net
# Example: https://mycompany-grafana.grafana.net
GRAFANA_URL=https://mycompany-grafana.grafana.net

# Option 2: Self-hosted Grafana with Docker
# - Start: docker run -p 3000:3000 grafana/grafana
# - URL: http://localhost:3000
# - Default creds: admin/admin
# Example: http://localhost:3000
# GRAFANA_URL=http://localhost:3000

# Grafana API Key
# 
# For Cloud:
# - Go to https://grafana.cloud
# - Settings → API Keys (or Org Settings → API tokens)
# - Create new API key with Editor role
# - Copy and paste here
# 
# For Self-hosted:
# - Go to http://localhost:3000
# - Click gear icon → API Keys
# - Create new API key with Editor role
#
# IMPORTANT: Don't commit this to git, use .env instead of .env.example
GRAFANA_API_KEY=glc_xxxxxYYYYzzzzzAAAAABBBB

# Data Source Configuration
# Name of the data source in Grafana (auto-created)
GRAFANA_DATASOURCE_NAME=ToolWeaver Analytics

# Data source type
# - sqlite: Direct SQLite connection (recommended)
# - postgresql: If using PostgreSQL instead
GRAFANA_DATASOURCE_TYPE=sqlite

# Grafana organization ID
# - Default: 1 (for single-org setups)
# - Multi-org: Use org-specific ID
GRAFANA_ORG_ID=1

# Auto-create dashboards
# - true: Automatically create sample dashboards on startup
# - false: Use existing dashboards
GRAFANA_AUTO_CREATE_DASHBOARDS=true

# Dashboard refresh interval
# - Format: 30s, 1m, 5m, 30m, 1h
# - Default: 1m (1 minute)
# - Smaller = more real-time but more database queries
# - Larger = less data, better performance
GRAFANA_DASHBOARD_REFRESH=1m


# ============================================================
# PHASE 5 ANALYTICS CONFIGURATION EXAMPLES
# ============================================================

# Example 1: Local Development (SQLite + Docker Grafana)
# ANALYTICS_DB_ENABLED=true
# ANALYTICS_DB_PATH=~/.toolweaver/analytics.db
# ANALYTICS_DB_RETENTION_DAYS=90
# GRAFANA_ENABLED=true
# GRAFANA_URL=http://localhost:3000
# GRAFANA_API_KEY=eyJrIjoiWXxxxxxxxxxxxxxx
# GRAFANA_DATASOURCE_NAME=ToolWeaver Dev
# GRAFANA_AUTO_CREATE_DASHBOARDS=true
# GRAFANA_DASHBOARD_REFRESH=30s

# Example 2: Production (SQLite + Grafana Cloud)
# ANALYTICS_DB_ENABLED=true
# ANALYTICS_DB_PATH=/var/toolweaver/analytics.db
# ANALYTICS_DB_RETENTION_DAYS=365
# GRAFANA_ENABLED=true
# GRAFANA_URL=https://yourcompany-grafana.grafana.net
# GRAFANA_API_KEY=glc_xxxxxxxxxxxxxx
# GRAFANA_DATASOURCE_NAME=ToolWeaver Production
# GRAFANA_AUTO_CREATE_DASHBOARDS=true
# GRAFANA_DASHBOARD_REFRESH=5m

# Example 3: Demo/Testing (Smaller retention)
# ANALYTICS_DB_ENABLED=true
# ANALYTICS_DB_PATH=~/.toolweaver/analytics_demo.db
# ANALYTICS_DB_RETENTION_DAYS=7
# GRAFANA_ENABLED=true
# GRAFANA_URL=http://localhost:3000
# GRAFANA_API_KEY=your-api-key
# GRAFANA_AUTO_CREATE_DASHBOARDS=true
# GRAFANA_DASHBOARD_REFRESH=1m
