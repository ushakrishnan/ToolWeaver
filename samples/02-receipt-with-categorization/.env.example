# ============================================================
# OCR CONFIGURATION
# ============================================================

# Use mock OCR data (default: true)
# Set to 'false' to enable real Azure Computer Vision OCR
USE_MOCK_OCR=true

# Azure Computer Vision endpoint (required if USE_MOCK_OCR=false)
# Example: https://my-resource.cognitiveservices.azure.com/
AZURE_CV_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/

# Azure CV authentication (choose one method):

# Option 1: API Key authentication
AZURE_CV_KEY=your-api-key-here

# Option 2: Azure AD authentication (set to true if using Azure AD)
AZURE_USE_AD=false

# ============================================================
# LARGE MODEL PLANNER (fill with your credentials; do not commit secrets)
# ============================================================

# Provider: openai, azure-openai, anthropic, or gemini
PLANNER_PROVIDER=azure-openai

# Model name (deployment name for Azure OpenAI)
PLANNER_MODEL=gpt-4o

# For Azure OpenAI (leave blank here; copy locally, do not commit secrets)
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_USE_AD=true
AZURE_OPENAI_ENDPOINT=https://your-azure-openai-endpoint/
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# Optional providers (leave blank unless using)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=


# ============================================================
# SMALL MODEL WORKERS (Phi-3 via Ollama)
# ============================================================

# Enable small model workers for parsing and categorization
USE_SMALL_MODEL=true

# Backend: 'ollama' (local) or 'azure' (Azure AI Foundry)
SMALL_MODEL_BACKEND=ollama

# Model name
WORKER_MODEL=phi3

# Ollama URL (if using Ollama)
OLLAMA_API_URL=http://localhost:11434


# ============================================================
# MONITORING (Optional)
# ============================================================

MONITORING_BACKENDS=local
TOOL_LOGS_DIR=.tool_logs
